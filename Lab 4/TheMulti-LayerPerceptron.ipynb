{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df96d1d6",
   "metadata": {},
   "source": [
    "# Lab 4: The Multi-Layer Perceptron\n",
    "## by Michael Doherty, Leilani Guzman, and Carson Pittman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c54396",
   "metadata": {},
   "source": [
    "Our goal is to predict what the child poverty rate for each county in the United States will be.\n",
    "\n",
    "Link to the dataset: https://www.kaggle.com/datasets/muonneutrino/us-census-demographic-data/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e687967",
   "metadata": {},
   "source": [
    "## 1. Load, Split, and Balance\n",
    "### 1.1 Loading the Data\n",
    "\n",
    "To begin, we need to load in the data and store it in a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c39736e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74001 entries, 0 to 74000\n",
      "Data columns (total 37 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   TractId           74001 non-null  int64  \n",
      " 1   State             74001 non-null  object \n",
      " 2   County            74001 non-null  object \n",
      " 3   TotalPop          74001 non-null  int64  \n",
      " 4   Men               74001 non-null  int64  \n",
      " 5   Women             74001 non-null  int64  \n",
      " 6   Hispanic          73305 non-null  float64\n",
      " 7   White             73305 non-null  float64\n",
      " 8   Black             73305 non-null  float64\n",
      " 9   Native            73305 non-null  float64\n",
      " 10  Asian             73305 non-null  float64\n",
      " 11  Pacific           73305 non-null  float64\n",
      " 12  VotingAgeCitizen  74001 non-null  int64  \n",
      " 13  Income            72885 non-null  float64\n",
      " 14  IncomeErr         72885 non-null  float64\n",
      " 15  IncomePerCap      73256 non-null  float64\n",
      " 16  IncomePerCapErr   73256 non-null  float64\n",
      " 17  Poverty           73159 non-null  float64\n",
      " 18  ChildPoverty      72891 non-null  float64\n",
      " 19  Professional      73190 non-null  float64\n",
      " 20  Service           73190 non-null  float64\n",
      " 21  Office            73190 non-null  float64\n",
      " 22  Construction      73190 non-null  float64\n",
      " 23  Production        73190 non-null  float64\n",
      " 24  Drive             73200 non-null  float64\n",
      " 25  Carpool           73200 non-null  float64\n",
      " 26  Transit           73200 non-null  float64\n",
      " 27  Walk              73200 non-null  float64\n",
      " 28  OtherTransp       73200 non-null  float64\n",
      " 29  WorkAtHome        73200 non-null  float64\n",
      " 30  MeanCommute       73055 non-null  float64\n",
      " 31  Employed          74001 non-null  int64  \n",
      " 32  PrivateWork       73190 non-null  float64\n",
      " 33  PublicWork        73190 non-null  float64\n",
      " 34  SelfEmployed      73190 non-null  float64\n",
      " 35  FamilyWork        73190 non-null  float64\n",
      " 36  Unemployment      73191 non-null  float64\n",
      "dtypes: float64(29), int64(6), object(2)\n",
      "memory usage: 20.9+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/acs2017_census_tract_data.csv\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412aa75f",
   "metadata": {},
   "source": [
    "As shown above, there are several missing datapoints in the dataset; seeing as the dataset is so large, we will remove the observations that have missing data.\n",
    "\n",
    "We also need to change the <code>State</code> and <code>County</code> attributes from strings to numeric data so we can use them in our neural network. For now, we will simply encode them as integers by mapping each string to an integer (such as mapping 'Alabama' to 1, 'Alaska' to 2, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19746816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 72718 entries, 0 to 74000\n",
      "Data columns (total 37 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   TractId           72718 non-null  int64  \n",
      " 1   State             72718 non-null  int64  \n",
      " 2   County            72718 non-null  int64  \n",
      " 3   TotalPop          72718 non-null  int64  \n",
      " 4   Men               72718 non-null  int64  \n",
      " 5   Women             72718 non-null  int64  \n",
      " 6   Hispanic          72718 non-null  float64\n",
      " 7   White             72718 non-null  float64\n",
      " 8   Black             72718 non-null  float64\n",
      " 9   Native            72718 non-null  float64\n",
      " 10  Asian             72718 non-null  float64\n",
      " 11  Pacific           72718 non-null  float64\n",
      " 12  VotingAgeCitizen  72718 non-null  int64  \n",
      " 13  Income            72718 non-null  float64\n",
      " 14  IncomeErr         72718 non-null  float64\n",
      " 15  IncomePerCap      72718 non-null  float64\n",
      " 16  IncomePerCapErr   72718 non-null  float64\n",
      " 17  Poverty           72718 non-null  float64\n",
      " 18  ChildPoverty      72718 non-null  float64\n",
      " 19  Professional      72718 non-null  float64\n",
      " 20  Service           72718 non-null  float64\n",
      " 21  Office            72718 non-null  float64\n",
      " 22  Construction      72718 non-null  float64\n",
      " 23  Production        72718 non-null  float64\n",
      " 24  Drive             72718 non-null  float64\n",
      " 25  Carpool           72718 non-null  float64\n",
      " 26  Transit           72718 non-null  float64\n",
      " 27  Walk              72718 non-null  float64\n",
      " 28  OtherTransp       72718 non-null  float64\n",
      " 29  WorkAtHome        72718 non-null  float64\n",
      " 30  MeanCommute       72718 non-null  float64\n",
      " 31  Employed          72718 non-null  int64  \n",
      " 32  PrivateWork       72718 non-null  float64\n",
      " 33  PublicWork        72718 non-null  float64\n",
      " 34  SelfEmployed      72718 non-null  float64\n",
      " 35  FamilyWork        72718 non-null  float64\n",
      " 36  Unemployment      72718 non-null  float64\n",
      "dtypes: float64(29), int64(8)\n",
      "memory usage: 21.1 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TractId</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>TotalPop</th>\n",
       "      <th>Men</th>\n",
       "      <th>Women</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>Native</th>\n",
       "      <th>...</th>\n",
       "      <th>Walk</th>\n",
       "      <th>OtherTransp</th>\n",
       "      <th>WorkAtHome</th>\n",
       "      <th>MeanCommute</th>\n",
       "      <th>Employed</th>\n",
       "      <th>PrivateWork</th>\n",
       "      <th>PublicWork</th>\n",
       "      <th>SelfEmployed</th>\n",
       "      <th>FamilyWork</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001020100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1845</td>\n",
       "      <td>899</td>\n",
       "      <td>946</td>\n",
       "      <td>2.4</td>\n",
       "      <td>86.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>881</td>\n",
       "      <td>74.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001020200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2172</td>\n",
       "      <td>1167</td>\n",
       "      <td>1005</td>\n",
       "      <td>1.1</td>\n",
       "      <td>41.6</td>\n",
       "      <td>54.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>852</td>\n",
       "      <td>75.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001020300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3385</td>\n",
       "      <td>1533</td>\n",
       "      <td>1852</td>\n",
       "      <td>8.0</td>\n",
       "      <td>61.4</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>23.1</td>\n",
       "      <td>1482</td>\n",
       "      <td>73.3</td>\n",
       "      <td>21.1</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001020400</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4267</td>\n",
       "      <td>2001</td>\n",
       "      <td>2266</td>\n",
       "      <td>9.6</td>\n",
       "      <td>80.3</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>25.9</td>\n",
       "      <td>1849</td>\n",
       "      <td>75.8</td>\n",
       "      <td>19.7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001020500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9965</td>\n",
       "      <td>5054</td>\n",
       "      <td>4911</td>\n",
       "      <td>0.9</td>\n",
       "      <td>77.5</td>\n",
       "      <td>16.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4787</td>\n",
       "      <td>71.4</td>\n",
       "      <td>24.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TractId  State  County  TotalPop   Men  Women  Hispanic  White  Black  \\\n",
       "0  1001020100      1       1      1845   899    946       2.4   86.3    5.2   \n",
       "1  1001020200      1       1      2172  1167   1005       1.1   41.6   54.5   \n",
       "2  1001020300      1       1      3385  1533   1852       8.0   61.4   26.5   \n",
       "3  1001020400      1       1      4267  2001   2266       9.6   80.3    7.1   \n",
       "4  1001020500      1       1      9965  5054   4911       0.9   77.5   16.4   \n",
       "\n",
       "   Native  ...  Walk  OtherTransp  WorkAtHome  MeanCommute  Employed  \\\n",
       "0     0.0  ...   0.5          0.0         2.1         24.5       881   \n",
       "1     0.0  ...   0.0          0.5         0.0         22.2       852   \n",
       "2     0.6  ...   1.0          0.8         1.5         23.1      1482   \n",
       "3     0.5  ...   1.5          2.9         2.1         25.9      1849   \n",
       "4     0.0  ...   0.8          0.3         0.7         21.0      4787   \n",
       "\n",
       "   PrivateWork  PublicWork  SelfEmployed  FamilyWork  Unemployment  \n",
       "0         74.2        21.2           4.5         0.0           4.6  \n",
       "1         75.9        15.0           9.0         0.0           3.4  \n",
       "2         73.3        21.1           4.8         0.7           4.7  \n",
       "3         75.8        19.7           4.5         0.0           6.1  \n",
       "4         71.4        24.1           4.5         0.0           2.3  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove rows with missing data\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# convert 'State' strings to integers\n",
    "unique_states = df['State'].unique()\n",
    "\n",
    "state_to_int = { }\n",
    "\n",
    "counter = 1\n",
    "\n",
    "for state in unique_states:\n",
    "    state_to_int[state] = counter\n",
    "    counter += 1\n",
    "\n",
    "# 'Alabama' = 1, 'Alaska' = 2, 'Arizona' = 3, etc.\n",
    "df['State'] = df['State'].map(state_to_int)\n",
    "\n",
    "# convert 'County' strings to integers\n",
    "unique_counties = df['County'].unique()\n",
    "\n",
    "county_to_int = { }\n",
    "\n",
    "counter = 1\n",
    "\n",
    "for county in unique_counties:\n",
    "    county_to_int[county] = counter\n",
    "    counter += 1\n",
    "    \n",
    "# 'Autauga County' = 1, 'Baldwin County' = 2, 'Barbour County' = 3, etc.\n",
    "df['County'] = df['County'].map(county_to_int)\n",
    "\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc65c7bd",
   "metadata": {},
   "source": [
    "We decided to keep the <code>County</code> variable instead of removing it. While the <code>State</code> variable gives us enough information to geographically represent each part of the country, we believe that the <code>County</code> variable allows us to break these geographic locations down even further (which we think is important, as it is often the case that different parts of a state have vast differences in the makeup of their population, especially in large states like Texas). Since we are predicting the child poverty rate for each county, we believe that being able to distinguish statistical features between counties is important. Thus, we will keep the <code>County</code> variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb5c918",
   "metadata": {},
   "source": [
    "### 1.2 Splitting the Dataset\n",
    "\n",
    "Now we need to split the dataset into training data and testing data. We'll use 80% of the data for training and 20% of the data for testing. It's important that we do this before balancing the dataset, as we only want to balance the training data; this is because the testing data should be a representative sample of the population, meaning it shouldn't necessarily be balanced (as a truly random sample of the population likely wouldn't be balanced either). We want our model to be able to correctly predict the <code>ChildPoverty</code> for any sample of data, regardless of if the data is balanced or not. Thus, we will split the dataset before only balancing the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6639c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns=[\"ChildPoverty\"])\n",
    "y = df[\"ChildPoverty\"]\n",
    "\n",
    "# 80% training, 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d89813",
   "metadata": {},
   "source": [
    "### 1.3 Balancing the Dataset\n",
    "\n",
    "Now that we have split our dataset into testing and training data, we need to balance the testing dataset; to do that, we'll split the data into four classes based on the quartiles for <code>ChildPoverty</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38dc7f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quartile 1 count: 14444\n",
      "Quartile 2 count: 14532\n",
      "Quartile 3 count: 14641\n",
      "Quartile 4 count: 14557\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "quartile_cutoffs = y_train.quantile([0.25, 0.5, 0.75])\n",
    "\n",
    "quartiles = []\n",
    "\n",
    "for val in y_train:\n",
    "    if val < quartile_cutoffs[0.25]:\n",
    "        quartiles.append(1) # Quartile 1\n",
    "    elif val < quartile_cutoffs[0.5]:\n",
    "        quartiles.append(2) # Quartile 2\n",
    "    elif val < quartile_cutoffs[0.75]:\n",
    "        quartiles.append(3) # Quartile 3\n",
    "    else:\n",
    "        quartiles.append(4) # Quartile 4\n",
    "        \n",
    "        \n",
    "print('Quartile 1 count:', quartiles.count(1))\n",
    "print('Quartile 2 count:', quartiles.count(2))\n",
    "print('Quartile 3 count:', quartiles.count(3))\n",
    "print('Quartile 4 count:', quartiles.count(4))\n",
    "        \n",
    "# X_train['ChildPovertyClass'] = quartiles\n",
    "y_train = quartiles\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "quartiles_test = []\n",
    "\n",
    "for val in y_test:\n",
    "    if val < quartile_cutoffs[0.25]:\n",
    "        quartiles_test.append(1) # Quartile 1\n",
    "    elif val < quartile_cutoffs[0.5]:\n",
    "        quartiles_test.append(2) # Quartile 2\n",
    "    elif val < quartile_cutoffs[0.75]:\n",
    "        quartiles_test.append(3) # Quartile 3\n",
    "    else:\n",
    "        quartiles_test.append(4) # Quartile 4\n",
    "\n",
    "# X_test['ChildPovertyClass'] = quartiles_test\n",
    "y_test = quartiles_test\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a916ca36",
   "metadata": {},
   "source": [
    "As shown above, by splitting the training data into quartiles (based off the values of <code>ChildPoverty</code> in <code>y_train</code>), we have about the same number of instances in each of the four classes. We believe this is the best method to balance the data, as it groups together instances that have similiar <code>ChildPoverty</code> values. **ADD MORE??**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a672773",
   "metadata": {},
   "source": [
    "## 2. Pre-Processing and Initial Modeling\n",
    "### 2.1 Two-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f5ff0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# Example from class\n",
    "\n",
    "class TwoLayerPerceptronBase(object):\n",
    "    def __init__(self, n_hidden=30,\n",
    "                 C=0.0, epochs=500, eta=0.001, random_state=None, minibatches=1):\n",
    "        np.random.seed(random_state)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.l2_C = C\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.minibatches = int(minibatches)\n",
    "        \n",
    "    @staticmethod\n",
    "    def _encode_labels(y):\n",
    "        onehot = pd.get_dummies(y).values.T\n",
    "        return onehot\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights using Glorot and He normalization.\"\"\"\n",
    "        init_bound = 4*np.sqrt(6. / (self.n_hidden + self.n_features_))\n",
    "        W1 = np.random.uniform(-init_bound, init_bound,(self.n_hidden, self.n_features_))\n",
    "        # reduce the final layer magnitude in order to balance the size of the gradients\n",
    "        # between \n",
    "        init_bound = 4*np.sqrt(6 / (self.n_output_ + self.n_hidden))\n",
    "        W2 = np.random.uniform(-init_bound, init_bound,(self.n_output_, self.n_hidden)) \n",
    "        \n",
    "        b1 = np.zeros((self.n_hidden, 1))\n",
    "        b2 = np.zeros((self.n_output_, 1))\n",
    "        \n",
    "        return W1, W2, b1, b2\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(z):\n",
    "        return expit(z)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _L2_reg(lambda_, W1, W2):\n",
    "        # Compute L2-regularization cost\n",
    "        # only compute for non-bias terms\n",
    "        return (lambda_/2.0) * np.sqrt(np.mean(W1[:, 1:] ** 2) + np.mean(W2[:, 1:] ** 2))\n",
    "    \n",
    "    def _cost(self,A3,Y_enc,W1,W2):\n",
    "        # Updated for cross entropy\n",
    "        #Get the objective function value\n",
    "        cost = -np.mean(np.nan_to_num((Y_enc*np.log(A3)+(1-Y_enc)*np.log(1-A3))))\n",
    "        L2_term = self._L2_reg(self.l2_C, W1, W2)\n",
    "        return cost + L2_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23920775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class TwoLayerPerceptron(TwoLayerPerceptronBase):\n",
    "    def _feedforward(self, X, W1, W2, b1, b2):\n",
    "        # Compute feedforward step\n",
    "        # X : Input layer with original features.\n",
    "        # W1: Weight matrix for input layer -> hidden layer.\n",
    "        # W2: Weight matrix for hidden layer -> output layer.\n",
    "        # a1-a3 : activations into layer (or output layer)\n",
    "        # z1-z2 : layer inputs\n",
    "\n",
    "        A1 = X.T\n",
    "        Z1 = W1 @ A1 + b1\n",
    "        A2 = self._sigmoid(Z1)\n",
    "        Z2 = W2 @ A2 + b2\n",
    "        A3 = self._sigmoid(Z2) \n",
    "        return A1, Z1, A2, Z2, A3\n",
    "    \n",
    "    def _get_gradient(self, A1, A2, A3, Z1, Z2, Y_enc, W1, W2):\n",
    "        # Compute gradient step using backpropagation\n",
    "        # vectorized backpropagation\n",
    "        V2 = (A3-Y_enc) # Updated for cross entropy\n",
    "        V1 = A2*(1-A2)*(W2.T @ V2)\n",
    "    \n",
    "        gradW2 = V2 @ A2.T\n",
    "        gradW1 = V1 @ A1.T\n",
    "        gradb2 = np.sum(V2, axis=1).reshape((-1,1))\n",
    "        gradb1 = np.sum(V1, axis=1).reshape((-1,1))\n",
    "        # regularize weights that are not bias terms\n",
    "        gradW1 += W1 * self.l2_C * 2\n",
    "        gradW2 += W2 * self.l2_C * 2 \n",
    "\n",
    "        return gradW1, gradW2, gradb1, gradb2\n",
    "        \n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Predict class labels\n",
    "        _, _, _, _, A3 = self._feedforward(X,self.W1,self.W2, self.b1, self.b2)\n",
    "        y_pred = self.unique_[np.argmax(A3, axis=0)]\n",
    "        return y_pred\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y, print_progress=False):\n",
    "        self.unique_ = np.unique(y) # Get the unique labels\n",
    "        # Learn weights from training data\n",
    "        X_data, y_data = X.copy(), y.copy()\n",
    "        Y_enc = self._encode_labels(y)\n",
    "       \n",
    "        # init weights and setup matrices\n",
    "        self.n_features_ = X_data.shape[1]\n",
    "        self.n_output_ = Y_enc.shape[0]\n",
    "        self.W1, self.W2, self.b1, self.b2= self._initialize_weights()\n",
    "       \n",
    "        num_samples = X_data.shape[0]\n",
    "       \n",
    "        self.cost_ = []\n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            if print_progress>0 and (i+1)%print_progress==0:\n",
    "                sys.stderr.write('\\rEpoch: %d/%d' % (i+1, self.epochs))\n",
    "                sys.stderr.flush()\n",
    "\n",
    "            ridx = np.random.permutation(y_data.shape[0])\n",
    "            X_data, Y_enc = X_data[ridx], Y_enc[:, ridx]\n",
    "\n",
    "            mini = np.array_split(range(y_data.shape[0]), self.minibatches)\n",
    "            mini_cost = []\n",
    "            for idx in mini:\n",
    "                # feedforward all instances\n",
    "                A1, Z1, A2, Z2, A3 = self._feedforward(X_data[idx],\n",
    "                                                       self.W1,\n",
    "                                                       self.W2, \n",
    "                                                       self.b1, \n",
    "                                                       self.b2)\n",
    "           \n",
    "                cost = self._cost(A3,Y_enc[:, idx],self.W1,self.W2)\n",
    "                mini_cost.append(cost)\n",
    "\n",
    "                # compute gradient via backpropagation\n",
    "                gradW1, gradW2, gradb1, gradb2 = self._get_gradient(A1=A1, A2=A2, A3=A3, Z1=Z1, Z2=Z2, Y_enc=Y_enc[:,idx],\n",
    "                                                W1=self.W1, W2=self.W2)\n",
    "\n",
    "\n",
    "                self.W1 -= self.eta * gradW1\n",
    "                self.W2 -= self.eta * gradW2\n",
    "                self.b1 -= self.eta * gradb1\n",
    "                self.b2 -= self.eta * gradb2\n",
    "\n",
    "            self.cost_.append(mini_cost)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e8f412e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 300/300"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted [4 4 4 4 4 4 4 4 4 4]\n",
      "Actual [2 4 3 1 1 1 3 1 1 3]\n",
      "Unique predicted values: [4]\n",
      "Accuracy: 0.2484185918591859\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "%matplotlib inline \n",
    "\n",
    "# Convert to numpy array\n",
    "X_train_np = np.array(X_train)\n",
    "y_train_np = np.array(y_train)\n",
    "X_test_np = np.array(X_test)\n",
    "y_test_np = np.array(y_test)\n",
    "\n",
    "neural_network = TwoLayerPerceptron(n_hidden=20, \n",
    "                                    C=5, # tradeoff L2 regularizer\n",
    "                                    epochs=300, # iterations\n",
    "                                    eta=.1,  # learning rate\n",
    "                                    random_state=1,\n",
    "                                    minibatches=len(X_train_np)/32)\n",
    "\n",
    "\n",
    "\n",
    "neural_network.fit(X_train_np, y_train_np, print_progress=50)\n",
    "yhat = neural_network.predict(X_test_np)\n",
    "\n",
    "# For Testing\n",
    "print('Predicted', yhat[:10])\n",
    "print(\"Actual\", y_test_np[:10])\n",
    "print('Unique predicted values:', np.unique(yhat))\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test_np,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "701ae4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "cost_avgs = [np.mean(x) for x in neural_network.cost_]\n",
    "\n",
    "plt.plot(range(len(cost_avgs)), cost_avgs, color='red')\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Only Target Encoded')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d7072c",
   "metadata": {},
   "source": [
    "### 2.2 Normalizing Continuous Numeric Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bf1caef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 300/300"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (14544, 1), indices imply (4, 14544)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 23\u001b[0m\n\u001b[0;32m     15\u001b[0m neural_network_2 \u001b[38;5;241m=\u001b[39m TwoLayerPerceptron(n_hidden\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, \n\u001b[0;32m     16\u001b[0m                                     C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, \u001b[38;5;66;03m# tradeoff L2 regularizer\u001b[39;00m\n\u001b[0;32m     17\u001b[0m                                     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m, \u001b[38;5;66;03m# iterations\u001b[39;00m\n\u001b[0;32m     18\u001b[0m                                     eta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,  \u001b[38;5;66;03m# learning rate\u001b[39;00m\n\u001b[0;32m     19\u001b[0m                                     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     20\u001b[0m                                     minibatches\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(X_train_norm_np)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m     22\u001b[0m neural_network_2\u001b[38;5;241m.\u001b[39mfit(X_train_norm_np, y_train_np, print_progress\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m yhat_2 \u001b[38;5;241m=\u001b[39m neural_network_2\u001b[38;5;241m.\u001b[39mpredict(X_test_norm)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m'\u001b[39m, accuracy_score(y_test_np, yhat_2))\n",
      "Cell \u001b[1;32mIn[6], line 39\u001b[0m, in \u001b[0;36mTwoLayerPerceptron.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# Predict class labels\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     _, _, _, _, A3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feedforward(X,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW1,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW2, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb2)\n\u001b[1;32m---> 39\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munique_[np\u001b[38;5;241m.\u001b[39margmax(A3, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)]\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y_pred\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:1242\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1241\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m-> 1242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124margmax\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:54\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     52\u001b[0m bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, method, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bound \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:47\u001b[0m, in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m     46\u001b[0m         result \u001b[38;5;241m=\u001b[39m asarray(result)\n\u001b[1;32m---> 47\u001b[0m     result \u001b[38;5;241m=\u001b[39m wrap(result)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:2107\u001b[0m, in \u001b[0;36mNDFrame.__array_wrap__\u001b[1;34m(self, result, context)\u001b[0m\n\u001b[0;32m   2105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m   2106\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_axes_dict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_AXIS_ORDERS, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 2107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(res, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39md)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__array_wrap__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:722\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    712\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    713\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    714\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    719\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    720\u001b[0m         )\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 722\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m ndarray_to_mgr(\n\u001b[0;32m    723\u001b[0m             data,\n\u001b[0;32m    724\u001b[0m             index,\n\u001b[0;32m    725\u001b[0m             columns,\n\u001b[0;32m    726\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    727\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    728\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    729\u001b[0m         )\n\u001b[0;32m    731\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:349\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    345\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[0;32m    346\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    347\u001b[0m )\n\u001b[1;32m--> 349\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (14544, 1), indices imply (4, 14544)"
     ]
    }
   ],
   "source": [
    "# Normalize the continuous features except for state and county\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X_train_norm = X_train.copy()\n",
    "X_test_norm = X_test.copy()\n",
    "\n",
    "# Normalize without removing state and county from the dataframe (ignore columns 1 and 2)\n",
    "X_train_norm.iloc[:, [0] + list(range(3, len(X_train.columns)))] = preprocessing.scale(X_train_norm.iloc[:, [0] + list(range(3, len(X_train.columns)))])\n",
    "X_test_norm.iloc[:, [0] + list(range(3, len(X_test.columns)))] = preprocessing.scale(X_test_norm.iloc[:, [0] + list(range(3, len(X_test.columns)))])\n",
    "\n",
    "# Convert to numpy array\n",
    "X_train_norm_np= np.array(X_train_norm)\n",
    "X_test_norm_np = np.array(X_test_norm)\n",
    "\n",
    "neural_network_2 = TwoLayerPerceptron(n_hidden=20, \n",
    "                                    C=5, # tradeoff L2 regularizer\n",
    "                                    epochs=300, # iterations\n",
    "                                    eta=0.1,  # learning rate\n",
    "                                    random_state=1,\n",
    "                                    minibatches=len(X_train_norm_np)/32)\n",
    "\n",
    "neural_network_2.fit(X_train_norm_np, y_train_np, print_progress=50)\n",
    "yhat_2 = neural_network_2.predict(X_test_norm)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test_np, yhat_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116da93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_avgs = [np.mean(x) for x in neural_network_2.cost_]\n",
    "\n",
    "plt.plot(range(len(cost_avgs)), cost_avgs, color='red')\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Normalized Data')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bc03d3",
   "metadata": {},
   "source": [
    "### 2.3 One Hot Encoding Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a7fb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode the state and county columns and normalize the continuous features, but keep the state and county columns in the final result\n",
    "from sklearn import preprocessing\n",
    "\n",
    " \n",
    "# One hot encode the state and county columns\n",
    "X_train_norm = pd.get_dummies(X_train_norm, columns=['State', 'County'])\n",
    "X_test_norm = pd.get_dummies(X_test_norm, columns=['State', 'County'])\n",
    "\n",
    "# Convert to numpy array\n",
    "# This is the final processed data that is normalized and one hot encoded\n",
    "\n",
    "X_train_norm_np = np.array(X_train_norm)\n",
    "X_test_norm_np = np.array(X_test_norm)\n",
    "\n",
    "neural_network_3 = TwoLayerPerceptron(n_hidden=20,\n",
    "                                        C=5, # tradeoff L2 regularizer\n",
    "                                        epochs=300, # iterations\n",
    "                                        eta=0.1,  # learning rate\n",
    "                                        random_state=1,\n",
    "                                        minibatches=len(X_train_norm_np)/32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6f7c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network_3 = TwoLayerPerceptron(n_hidden=20,\n",
    "                                    C=5, # tradeoff L2 regularizer\n",
    "                                    epochs=300, # iterations\n",
    "                                    eta=0.1,  # learning rate\n",
    "                                    random_state=1,\n",
    "                                    minibatches=len(X_train_np)/32)\n",
    "\n",
    "neural_network_3.fit(X_train_norm_np, y_train_np, print_progress=50)\n",
    "yhat_3 = neural_network_3.predict(X_test_norm_np)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test_np, yhat_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f827743a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_avgs = [np.mean(x) for x in neural_network_3.cost_]\n",
    "\n",
    "plt.plot(range(len(cost_avgs)), cost_avgs, color='red')\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Normalization and One-Hot Encoding')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ab6654",
   "metadata": {},
   "source": [
    "### 2.4 Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7d56f6",
   "metadata": {},
   "source": [
    "## 3. Modeling\n",
    "### 3.1 Adding a Third Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48bcff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeLayerPerceptron(TwoLayerPerceptron):\n",
    "    def __init__(self, n_hidden_1=30, n_hidden_2=30,\n",
    "             C=0.0, epochs=500, eta=0.001, random_state=None, minibatches=1):\n",
    "        np.random.seed(random_state)\n",
    "        self.n_hidden_1 = n_hidden_1\n",
    "        self.n_hidden_2 = n_hidden_2\n",
    "        self.l2_C = C\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.minibatches = int(minibatches)\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights using Glorot and He normalization.\"\"\"\n",
    "        init_bound = 4*np.sqrt(6. / (self.n_hidden_1 + self.n_features_))\n",
    "        W1 = np.random.uniform(-init_bound, init_bound,(self.n_hidden_1, self.n_features_))\n",
    "\n",
    "        init_bound = 4*np.sqrt(6 / (self.n_hidden_2 + self.n_hidden_1))\n",
    "        W2 = np.random.uniform(-init_bound, init_bound,(self.n_hidden_2, self.n_hidden_1))\n",
    "        \n",
    "        # reduce the final layer magnitude in order to balance the size of the gradients\n",
    "        # between \n",
    "        init_bound = 4*np.sqrt(6 / (self.n_output_ + self.n_hidden_2))\n",
    "        W3 = np.random.uniform(-init_bound, init_bound,(self.n_output_, self.n_hidden_2)) \n",
    "        \n",
    "        b1 = np.zeros((self.n_hidden_1, 1))\n",
    "        b2 = np.zeros((self.n_hidden_2, 1))\n",
    "        b3 = np.zeros((self.n_output_, 1))\n",
    "        \n",
    "        return W1, W2, W3, b1, b2, b3\n",
    "\n",
    "    @staticmethod\n",
    "    def _L2_reg(lambda_, W1, W2, W3):\n",
    "        # Compute L2-regularization cost\n",
    "        # only compute for non-bias terms\n",
    "        return (lambda_/2.0) * np.sqrt(np.mean(W1[:, 1:] ** 2) + np.mean(W2[:, 1:] ** 2) + np.mean(W3[:, 1:] ** 2)) \n",
    "    \n",
    "    def _cost(self,A4,Y_enc,W1,W2,W3):\n",
    "        # Updated for cross entropy\n",
    "        #Get the objective function value\n",
    "        cost = -np.mean(np.nan_to_num((Y_enc*np.log(A4)+(1-Y_enc)*np.log(1-A4))))\n",
    "        L2_term = self._L2_reg(self.l2_C, W1, W2, W3)\n",
    "        return cost + L2_term\n",
    "    \n",
    "    def _feedforward(self, X, W1, W2, W3, b1, b2, b3):\n",
    "        A1 = X.T\n",
    "        Z1 = W1 @ A1 + b1\n",
    "        A2 = self._sigmoid(Z1)\n",
    "        Z2 = W2 @ A2 + b2\n",
    "        A3 = self._sigmoid(Z2)\n",
    "        Z3 = W3 @ A3 + b3\n",
    "        A4 = self._sigmoid(Z3)\n",
    "        return A1, Z1, A2, Z2, A3, Z3, A4\n",
    "    \n",
    "    def _get_gradient(self, A1, A2, A3, A4, Z1, Z2, Z3, Y_enc, W1, W2, W3):\n",
    "        # Compute gradient step using backpropagation\n",
    "        # vectorized backpropagation\n",
    "        \n",
    "        V3 = (A4-Y_enc)\n",
    "        V2 = A3*(1-A3)*(W3.T @ V3)\n",
    "        V1 = A2*(1-A2)*(W2.T @ V2)\n",
    "    \n",
    "        gradW3 = V3 @ A3.T\n",
    "        gradW2 = V2 @ A2.T\n",
    "        gradW1 = V1 @ A1.T\n",
    "        gradb3 = np.sum(V3, axis=1).reshape((-1,1))\n",
    "        gradb2 = np.sum(V2, axis=1).reshape((-1,1))\n",
    "        gradb1 = np.sum(V1, axis=1).reshape((-1,1))\n",
    "        \n",
    "        # regularize weights that are not bias terms\n",
    "        gradW3 += W3 * self.l2_C * 2 \n",
    "        gradW2 += W2 * self.l2_C * 2 \n",
    "        gradW1 += W1 * self.l2_C * 2\n",
    "        \n",
    "        return gradW1, gradW2, gradW3, gradb1, gradb2, gradb3\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Predict class labels\n",
    "        _, _, _, _, _, _, A4 = self._feedforward(X,self.W1,self.W2,self.W3,self.b1,self.b2,self.b3)\n",
    "        y_pred = self.unique_[np.argmax(A4, axis=0)]\n",
    "        return y_pred\n",
    "    \n",
    "    def fit(self, X, y, print_progress=False):\n",
    "        self.unique_ = np.unique(y) # Get the unique labels\n",
    "        # Learn weights from training data\n",
    "        X_data, y_data = X.copy(), y.copy()\n",
    "        Y_enc = self._encode_labels(y)\n",
    "       \n",
    "        # init weights and setup matrices\n",
    "        self.n_features_ = X_data.shape[1]\n",
    "        self.n_output_ = Y_enc.shape[0]\n",
    "        self.W1, self.W2, self.W3, self.b1, self.b2, self.b3 = self._initialize_weights()\n",
    "       \n",
    "        num_samples = X_data.shape[0]\n",
    "       \n",
    "        self.cost_ = []\n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            if print_progress>0 and (i+1)%print_progress==0:\n",
    "                sys.stderr.write('\\rEpoch: %d/%d' % (i+1, self.epochs))\n",
    "                sys.stderr.flush()\n",
    "\n",
    "            ridx = np.random.permutation(y_data.shape[0])\n",
    "            X_data, Y_enc = X_data[ridx], Y_enc[:, ridx]\n",
    "\n",
    "            mini = np.array_split(range(y_data.shape[0]), self.minibatches)\n",
    "            mini_cost = []\n",
    "            for idx in mini:\n",
    "                # feedforward all instances\n",
    "                A1, Z1, A2, Z2, A3, Z3, A4 = self._feedforward(X_data[idx],\n",
    "                                                               self.W1,\n",
    "                                                               self.W2,\n",
    "                                                               self.W3,\n",
    "                                                               self.b1, \n",
    "                                                               self.b2,\n",
    "                                                               self.b3)\n",
    "           \n",
    "                cost = self._cost(A4,Y_enc[:, idx],self.W1,self.W2,self.W3)\n",
    "                mini_cost.append(cost)\n",
    "\n",
    "                # compute gradient via backpropagation\n",
    "                gradW1, gradW2, gradW3, gradb1, gradb2, gradb3 = self._get_gradient(A1=A1, A2=A2, A3=A3, A4=A4, \n",
    "                                                                 Z1=Z1, Z2=Z2, Z3=Z3, Y_enc=Y_enc[:,idx],\n",
    "                                                                 W1=self.W1, W2=self.W2, W3=self.W3)\n",
    "\n",
    "                self.W1 -= self.eta * gradW1\n",
    "                self.W2 -= self.eta * gradW2\n",
    "                self.W3 -= self.eta * gradW3\n",
    "                self.b1 -= self.eta * gradb1\n",
    "                self.b2 -= self.eta * gradb2\n",
    "                self.b3 -= self.eta * gradb3\n",
    "\n",
    "            self.cost_.append(mini_cost)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccd2558",
   "metadata": {},
   "source": [
    "### 3.2 Adding a Fourth Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b590a33e",
   "metadata": {},
   "source": [
    "### 3.3 Adding a Fifth Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d04758",
   "metadata": {},
   "source": [
    "### 3.4 Implementing Adaptive Learning (RENAME TO WHICHEVER ONE WE CHOOSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35eefc5",
   "metadata": {},
   "source": [
    "## 4. Adaptive Momentum (AdaM)\n",
    "### 4.1 Implementing Adaptive Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11c1fac",
   "metadata": {},
   "source": [
    "### 4.2 Quantifying the Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d063e18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
