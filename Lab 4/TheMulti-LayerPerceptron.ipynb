{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df96d1d6",
   "metadata": {},
   "source": [
    "# Lab 4: The Multi-Layer Perceptron\n",
    "## by Michael Doherty, Leilani Guzman, and Carson Pittman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c54396",
   "metadata": {},
   "source": [
    "Our goal is to predict what the child poverty rate for each county in the United States will be.\n",
    "\n",
    "Link to the dataset: https://www.kaggle.com/datasets/muonneutrino/us-census-demographic-data/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e687967",
   "metadata": {},
   "source": [
    "## 1. Load, Split, and Balance\n",
    "### 1.1 Loading the Data\n",
    "\n",
    "To begin, we need to load in the data and store it in a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c39736e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74001 entries, 0 to 74000\n",
      "Data columns (total 37 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   TractId           74001 non-null  int64  \n",
      " 1   State             74001 non-null  object \n",
      " 2   County            74001 non-null  object \n",
      " 3   TotalPop          74001 non-null  int64  \n",
      " 4   Men               74001 non-null  int64  \n",
      " 5   Women             74001 non-null  int64  \n",
      " 6   Hispanic          73305 non-null  float64\n",
      " 7   White             73305 non-null  float64\n",
      " 8   Black             73305 non-null  float64\n",
      " 9   Native            73305 non-null  float64\n",
      " 10  Asian             73305 non-null  float64\n",
      " 11  Pacific           73305 non-null  float64\n",
      " 12  VotingAgeCitizen  74001 non-null  int64  \n",
      " 13  Income            72885 non-null  float64\n",
      " 14  IncomeErr         72885 non-null  float64\n",
      " 15  IncomePerCap      73256 non-null  float64\n",
      " 16  IncomePerCapErr   73256 non-null  float64\n",
      " 17  Poverty           73159 non-null  float64\n",
      " 18  ChildPoverty      72891 non-null  float64\n",
      " 19  Professional      73190 non-null  float64\n",
      " 20  Service           73190 non-null  float64\n",
      " 21  Office            73190 non-null  float64\n",
      " 22  Construction      73190 non-null  float64\n",
      " 23  Production        73190 non-null  float64\n",
      " 24  Drive             73200 non-null  float64\n",
      " 25  Carpool           73200 non-null  float64\n",
      " 26  Transit           73200 non-null  float64\n",
      " 27  Walk              73200 non-null  float64\n",
      " 28  OtherTransp       73200 non-null  float64\n",
      " 29  WorkAtHome        73200 non-null  float64\n",
      " 30  MeanCommute       73055 non-null  float64\n",
      " 31  Employed          74001 non-null  int64  \n",
      " 32  PrivateWork       73190 non-null  float64\n",
      " 33  PublicWork        73190 non-null  float64\n",
      " 34  SelfEmployed      73190 non-null  float64\n",
      " 35  FamilyWork        73190 non-null  float64\n",
      " 36  Unemployment      73191 non-null  float64\n",
      "dtypes: float64(29), int64(6), object(2)\n",
      "memory usage: 20.9+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/acs2017_census_tract_data.csv\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412aa75f",
   "metadata": {},
   "source": [
    "As shown above, there are several missing datapoints in the dataset; seeing as the dataset is so large, we will remove the observations that have missing data.\n",
    "\n",
    "We also need to change the <code>State</code> and <code>County</code> attributes from strings to numeric data so we can use them in our neural network. For now, we will simply encode them as integers by mapping each string to an integer (such as mapping 'Alabama' to 1, 'Alaska' to 2, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19746816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 72718 entries, 0 to 74000\n",
      "Data columns (total 37 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   TractId           72718 non-null  int64  \n",
      " 1   State             72718 non-null  int64  \n",
      " 2   County            72718 non-null  int64  \n",
      " 3   TotalPop          72718 non-null  int64  \n",
      " 4   Men               72718 non-null  int64  \n",
      " 5   Women             72718 non-null  int64  \n",
      " 6   Hispanic          72718 non-null  float64\n",
      " 7   White             72718 non-null  float64\n",
      " 8   Black             72718 non-null  float64\n",
      " 9   Native            72718 non-null  float64\n",
      " 10  Asian             72718 non-null  float64\n",
      " 11  Pacific           72718 non-null  float64\n",
      " 12  VotingAgeCitizen  72718 non-null  int64  \n",
      " 13  Income            72718 non-null  float64\n",
      " 14  IncomeErr         72718 non-null  float64\n",
      " 15  IncomePerCap      72718 non-null  float64\n",
      " 16  IncomePerCapErr   72718 non-null  float64\n",
      " 17  Poverty           72718 non-null  float64\n",
      " 18  ChildPoverty      72718 non-null  float64\n",
      " 19  Professional      72718 non-null  float64\n",
      " 20  Service           72718 non-null  float64\n",
      " 21  Office            72718 non-null  float64\n",
      " 22  Construction      72718 non-null  float64\n",
      " 23  Production        72718 non-null  float64\n",
      " 24  Drive             72718 non-null  float64\n",
      " 25  Carpool           72718 non-null  float64\n",
      " 26  Transit           72718 non-null  float64\n",
      " 27  Walk              72718 non-null  float64\n",
      " 28  OtherTransp       72718 non-null  float64\n",
      " 29  WorkAtHome        72718 non-null  float64\n",
      " 30  MeanCommute       72718 non-null  float64\n",
      " 31  Employed          72718 non-null  int64  \n",
      " 32  PrivateWork       72718 non-null  float64\n",
      " 33  PublicWork        72718 non-null  float64\n",
      " 34  SelfEmployed      72718 non-null  float64\n",
      " 35  FamilyWork        72718 non-null  float64\n",
      " 36  Unemployment      72718 non-null  float64\n",
      "dtypes: float64(29), int64(8)\n",
      "memory usage: 21.1 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TractId</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>TotalPop</th>\n",
       "      <th>Men</th>\n",
       "      <th>Women</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>Native</th>\n",
       "      <th>...</th>\n",
       "      <th>Walk</th>\n",
       "      <th>OtherTransp</th>\n",
       "      <th>WorkAtHome</th>\n",
       "      <th>MeanCommute</th>\n",
       "      <th>Employed</th>\n",
       "      <th>PrivateWork</th>\n",
       "      <th>PublicWork</th>\n",
       "      <th>SelfEmployed</th>\n",
       "      <th>FamilyWork</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001020100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1845</td>\n",
       "      <td>899</td>\n",
       "      <td>946</td>\n",
       "      <td>2.4</td>\n",
       "      <td>86.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>881</td>\n",
       "      <td>74.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001020200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2172</td>\n",
       "      <td>1167</td>\n",
       "      <td>1005</td>\n",
       "      <td>1.1</td>\n",
       "      <td>41.6</td>\n",
       "      <td>54.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>852</td>\n",
       "      <td>75.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001020300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3385</td>\n",
       "      <td>1533</td>\n",
       "      <td>1852</td>\n",
       "      <td>8.0</td>\n",
       "      <td>61.4</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>23.1</td>\n",
       "      <td>1482</td>\n",
       "      <td>73.3</td>\n",
       "      <td>21.1</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001020400</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4267</td>\n",
       "      <td>2001</td>\n",
       "      <td>2266</td>\n",
       "      <td>9.6</td>\n",
       "      <td>80.3</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>25.9</td>\n",
       "      <td>1849</td>\n",
       "      <td>75.8</td>\n",
       "      <td>19.7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001020500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9965</td>\n",
       "      <td>5054</td>\n",
       "      <td>4911</td>\n",
       "      <td>0.9</td>\n",
       "      <td>77.5</td>\n",
       "      <td>16.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4787</td>\n",
       "      <td>71.4</td>\n",
       "      <td>24.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TractId  State  County  TotalPop   Men  Women  Hispanic  White  Black  \\\n",
       "0  1001020100      1       1      1845   899    946       2.4   86.3    5.2   \n",
       "1  1001020200      1       1      2172  1167   1005       1.1   41.6   54.5   \n",
       "2  1001020300      1       1      3385  1533   1852       8.0   61.4   26.5   \n",
       "3  1001020400      1       1      4267  2001   2266       9.6   80.3    7.1   \n",
       "4  1001020500      1       1      9965  5054   4911       0.9   77.5   16.4   \n",
       "\n",
       "   Native  ...  Walk  OtherTransp  WorkAtHome  MeanCommute  Employed  \\\n",
       "0     0.0  ...   0.5          0.0         2.1         24.5       881   \n",
       "1     0.0  ...   0.0          0.5         0.0         22.2       852   \n",
       "2     0.6  ...   1.0          0.8         1.5         23.1      1482   \n",
       "3     0.5  ...   1.5          2.9         2.1         25.9      1849   \n",
       "4     0.0  ...   0.8          0.3         0.7         21.0      4787   \n",
       "\n",
       "   PrivateWork  PublicWork  SelfEmployed  FamilyWork  Unemployment  \n",
       "0         74.2        21.2           4.5         0.0           4.6  \n",
       "1         75.9        15.0           9.0         0.0           3.4  \n",
       "2         73.3        21.1           4.8         0.7           4.7  \n",
       "3         75.8        19.7           4.5         0.0           6.1  \n",
       "4         71.4        24.1           4.5         0.0           2.3  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove rows with missing data\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# convert 'State' strings to integers\n",
    "unique_states = df['State'].unique()\n",
    "\n",
    "state_to_int = { }\n",
    "\n",
    "counter = 1\n",
    "\n",
    "for state in unique_states:\n",
    "    state_to_int[state] = counter\n",
    "    counter += 1\n",
    "\n",
    "# 'Alabama' = 1, 'Alaska' = 2, 'Arizona' = 3, etc.\n",
    "df['State'] = df['State'].map(state_to_int)\n",
    "\n",
    "# convert 'County' strings to integers\n",
    "unique_counties = df['County'].unique()\n",
    "\n",
    "county_to_int = { }\n",
    "\n",
    "counter = 1\n",
    "\n",
    "for county in unique_counties:\n",
    "    county_to_int[county] = counter\n",
    "    counter += 1\n",
    "    \n",
    "# 'Autauga County' = 1, 'Baldwin County' = 2, 'Barbour County' = 3, etc.\n",
    "df['County'] = df['County'].map(county_to_int)\n",
    "\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc65c7bd",
   "metadata": {},
   "source": [
    "We decided to keep the <code>County</code> variable instead of removing it. While the <code>State</code> variable gives us enough information to geographically represent each part of the country, we believe that the <code>County</code> variable allows us to break these geographic locations down even further (which we think is important, as it is often the case that different parts of a state have vast differences in the makeup of their population, especially in large states like Texas). Since we are predicting the child poverty rate for each county, we believe that being able to distinguish statistical features between counties is important. Thus, we will keep the <code>County</code> variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb5c918",
   "metadata": {},
   "source": [
    "### 1.2 Splitting the Dataset\n",
    "\n",
    "Now we need to split the dataset into training data and testing data. We'll use 80% of the data for training and 20% of the data for testing. It's important that we do this before balancing the dataset, as we only want to balance the training data; this is because the testing data should be a representative sample of the population, meaning it shouldn't necessarily be balanced (as a truly random sample of the population likely wouldn't be balanced either). We want our model to be able to correctly predict the <code>ChildPoverty</code> for any sample of data, regardless of if the data is balanced or not. Thus, we will split the dataset before only balancing the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6639c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns=[\"ChildPoverty\"])\n",
    "y = df[\"ChildPoverty\"]\n",
    "\n",
    "# 80% training, 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d89813",
   "metadata": {},
   "source": [
    "### 1.3 Balancing the Dataset\n",
    "\n",
    "Now that we have split our dataset into testing and training data, we need to balance the testing dataset; to do that, we'll split the data into four classes based on the quartiles for <code>ChildPoverty</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38dc7f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quartile 1 count: 14524\n",
      "Quartile 2 count: 14472\n",
      "Quartile 3 count: 14625\n",
      "Quartile 4 count: 14553\n"
     ]
    }
   ],
   "source": [
    "quartile_cutoffs = y_train.quantile([0.25, 0.5, 0.75])\n",
    "\n",
    "quartiles = []\n",
    "\n",
    "for val in y_train:\n",
    "    if val < quartile_cutoffs[0.25]:\n",
    "        quartiles.append('Quartile 1')\n",
    "    elif val < quartile_cutoffs[0.5]:\n",
    "        quartiles.append('Quartile 2')\n",
    "    elif val < quartile_cutoffs[0.75]:\n",
    "        quartiles.append('Quartile 3')\n",
    "    else:\n",
    "        quartiles.append('Quartile 4')\n",
    "        \n",
    "        \n",
    "print('Quartile 1 count:', quartiles.count('Quartile 1'))\n",
    "print('Quartile 2 count:', quartiles.count('Quartile 2'))\n",
    "print('Quartile 3 count:', quartiles.count('Quartile 3'))\n",
    "print('Quartile 4 count:', quartiles.count('Quartile 4'))\n",
    "        \n",
    "X_train['ChildPovertyClass'] = quartiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a916ca36",
   "metadata": {},
   "source": [
    "As shown above, by splitting the training data into quartiles (based off the values of <code>ChildPoverty</code> in <code>y_train</code>), we have about the same number of instances in each of the four classes. We believe this is the best method to balance the data, as it groups together instances that have similiar <code>ChildPoverty</code> values. **ADD MORE??**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a672773",
   "metadata": {},
   "source": [
    "## 2. Pre-Processing and Initial Modeling\n",
    "### 2.1 Two-Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d7072c",
   "metadata": {},
   "source": [
    "### 2.2 Normalizing Continuous Numeric Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bc03d3",
   "metadata": {},
   "source": [
    "### 2.3 One Hot Encoding Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ab6654",
   "metadata": {},
   "source": [
    "### 2.4 Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7d56f6",
   "metadata": {},
   "source": [
    "## 3. Modeling\n",
    "### 3.1 Adding a Third Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccd2558",
   "metadata": {},
   "source": [
    "### 3.2 Adding a Fourth Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b590a33e",
   "metadata": {},
   "source": [
    "### 3.3 Adding a Fifth Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d04758",
   "metadata": {},
   "source": [
    "### 3.4 Implementing Adaptive Learning (RENAME TO WHICHEVER ONE WE CHOOSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35eefc5",
   "metadata": {},
   "source": [
    "## 4. Adaptive Momentum (AdaM)\n",
    "### 4.1 Implementing Adaptive Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11c1fac",
   "metadata": {},
   "source": [
    "### 4.2 Quantifying the Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d063e18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
