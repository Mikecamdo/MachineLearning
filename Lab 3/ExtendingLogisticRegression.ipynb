{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d35a951",
   "metadata": {},
   "source": [
    "# Lab 3: Extending Logistic Regression\n",
    "## by Michael Doherty, Leilani Guzman, and Carson Pittman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9660f3bc",
   "metadata": {},
   "source": [
    "## 1. Business Understanding\n",
    "\n",
    "In 1633, the Japanese government, feeling threatened by Spanish and Portugese influence within their country, banned foreign goods as part of their isolationist foreign policy (called [Sakoku](https://en.wikipedia.org/wiki/Sakoku)). As part of this ban, European playing cards were forbidden, so Japanese playing cards, called [hanafuda](https://lammuseum.wfu.edu/2021/12/japanese-hanafuda-cards/), were developed; however, hanafuda struggled to gain popularity among the Japanese populace. Centuries later, on November 22, 1859 in Kyoto, Japan, a man named Fusajiro Yamauchi was born. An aspiring artist and entrepreneur, Yamauchi saw an opportunity with hanafuda, so in 1889 he opened a shop to sell his own handcrafted cards. What was the name of that shop? [Nintendo Koppai](https://www.lifewire.com/fusajiro-yamauchi-founder-of-nintendo-729584) (which was later shortened to just Nintendo).\n",
    "\n",
    "While Fusajiro Yamauchi would never know it, his card company would eventually become one of the biggest video game companies in the world. Since the mid-twentieth century, advancements in technology have propelled video games to become a multi-billion dollar industry. Yet, not all video games are made equal; from sports games like the [FIFA series](https://en.wikipedia.org/wiki/FIFA_(video_game_series)) to puzzle games like [Tetris](https://en.wikipedia.org/wiki/Tetris), there are several genres that a video game can belong to.\n",
    "\n",
    "The dataset we've selected, titled \"Global Video Game Sales\", was created to analyze how a video game's genre relates to the platform it was released on, its publisher, and its sales (both globally and in various regions). The dataset consists of 16,600 instances with 11 multivariate attributes, comprised of numeric and categorical data types.\n",
    "\n",
    "Ultimately, the prediction task for this dataset is to determine what a video game's genre is. Who might be interested in this research? For starters, video game companies may be interested to see which video game genre has the best sales. They may also find that certain genres are more popular in some markets than others (such as puzzle games being popular in Japan and sports games being popular in Europe). This information can help inform their strategies on what types of games they should make and where they should focus their marketing efforts. The prediction model created would be mostly used for offline analysis (as there aren't enough video games being created all the time that would justify having a deployed model).\n",
    "\n",
    "So what does a good prediction algorithm for this dataset look like? There are several factors that need to be considered:\n",
    "- **Finding Useful Trends**: One of the most important factors for the prediction algorithm is being able to find clear trends relating to a video game's genre. For example, finding that Nintendo games sell best in Japan, or that the most profitable video game genre is Shooter games, would be useful information that video game companies could use to make decisions regarding future video games, where to market their products more, etc.\n",
    "- **Accuracy**: How accurate the prediction algorithm is at classifying video game genres is one of the most important aspects. The more accurate the prediction algorithm is, the more reliable the trends will be that we derive from the prediction algorithm. Thus, we want the accuracy to be as high as possible; at minimum, it should be higher than 50%, and ideally it would have  an accuracy greater than 90%.  \n",
    "\n",
    "Thus, there are several aspects that need to be considered when trying to create a reliable prediction model. The data derived from the model should help companies make informed decisions on what types of video games to make, where they should advertise certain types of games more heavily, Ultimately, any good prediction model would need to prove useful to video game companies by providing useful insights that can help them increase their profits.\n",
    "\n",
    "Link to the dataset: https://www.kaggle.com/datasets/thedevastator/global-video-game-sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e3860f",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd39165",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\carso\\AppData\\Local\\Programs\\Python\\Python39\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/carso/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/vgsales.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def4f8da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()\n",
    "rows_with_null_year = df[df[\"Year\"].isna()]\n",
    "rows_with_null_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e634c503",
   "metadata": {},
   "source": [
    "A lot of the missing data can be found in the dataset... (Madden NFL 2004 has multiple entries for each platform it was released on, and the other entries say it came out in 2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797142e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Cleaning with Aggregation\n",
    "\n",
    "df = df.groupby(\"Name\").aggregate({'Rank': 'first', 'Platform': 'first', 'Name': 'first', 'Year': 'first', 'Genre': 'first', 'Publisher': 'last', 'NA_Sales': 'sum', 'EU_Sales': 'sum', 'JP_Sales': 'sum', 'Other_Sales': 'sum', 'Global_Sales': 'sum' })\n",
    "del df[\"Platform\"]\n",
    "del df[\"Rank\"]\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f1238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Cleaning Without Aggregation\n",
    "\n",
    "df = df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160774d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\carso\\AppData\\Local\\Programs\\Python\\Python39\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/carso/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#One Hot Encoding\n",
    "\n",
    "df_onehot = pd.get_dummies(df, columns=['Publisher', 'Genre'])\n",
    "\n",
    "df_onehot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c79e080",
   "metadata": {},
   "source": [
    "## 3. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f90ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "\n",
    "# Binary Logistic Regression using vectorized implementation\n",
    "\n",
    "class BinaryLogisticRegression:\n",
    "    # Adjust default values for iterations and C as needed\n",
    "    def __init__(self, eta, iterations=20, C=0.001, penalty='l2'):\n",
    "        self.eta = eta          # The learning rate\n",
    "        self.iterations = iterations\n",
    "        self.C = C\n",
    "        self.penalty = penalty\n",
    "    def __str__(self):\n",
    "        if(hasattr(self, 'weights_')):\n",
    "            return \"Binary Logistic Regression Object with coefficients:\\n\" + str(self.weights_)\n",
    "        return 'Binary Logistic Regression Object is untrained'\n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_bias(X):\n",
    "        # Add a column of float ones to X\n",
    "        return np.hstack((np.ones((X.shape[0],1)), X))\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        return expit(theta)\n",
    "    \n",
    "    def _get_gradient(self, X, y):\n",
    "        y_diff = y - self.predict_proba(X, add_bias=False).ravel()\n",
    "        gradient = np.mean(X * y_diff[:,np.newaxis], axis = 0)\n",
    "        gradient = gradient.reshape(self.weights_.shape)\n",
    "        # Based on penalty type, add the appropriate term to the gradient\n",
    "        if self.penalty == 'l1':\n",
    "            # Double check this, not sure\n",
    "            gradient[1:] += self.C * sum(abs(self.weights_[1:]))\n",
    "        elif self.penalty == 'l2':\n",
    "            # Double check this, not sure\n",
    "            gradient[1:] += self.C * sum(self.weights_[1:]**2)\n",
    "        elif self.penalty == 'both':\n",
    "            gradient[1:] += self.C * sum(self.weights_[1:]**2) + self.C * sum(abs(self.weights_[1:]))\n",
    "        elif self.penalty == 'none':\n",
    "            pass\n",
    "        return gradient\n",
    "    \n",
    "    def predict_proba(self, X, add_bias=True):\n",
    "        print(type(X[0][0]))\n",
    "        X_bias = self._add_bias(X) if add_bias else X\n",
    "        return self._sigmoid(X_bias @ self.weights_)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return (self.predict_proba(X) > 0.5)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X_bias = self._add_bias(X)\n",
    "        num_samples, num_features = X_bias.shape\n",
    "        self.weights_ = np.zeros((num_features,1))    # Creating the weight vector\n",
    "        print (self.weights_.shape)\n",
    "\n",
    "        for _ in range(self.iterations):\n",
    "            gradient = self._get_gradient(X_bias, y)\n",
    "            self.weights_ += self.eta * gradient\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c0d9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import ma\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "## Optimizing 1: Steepest Ascent/Line Search\n",
    "\n",
    "class LineSearchLogisticRegression(BinaryLogisticRegression):\n",
    "    def __init__(self, line_iterations=0.0, **kwds):\n",
    "        self.line_iterations = line_iterations\n",
    "        super().__init__(**kwds)\n",
    "\n",
    "        @staticmethod\n",
    "        def objective_function(eta, X, y, w, gradient, C):\n",
    "            w_new = w - gradient*eta\n",
    "            gradient_new = expit(X @ w_new)\n",
    "            return -np.sum(ma.log(g[y==1]))-ma.sum(ma.log(1-gradient_new[y==0])) + C*sum(w_new**2)\n",
    "        \n",
    "        def fit(self, X, y):\n",
    "            X_bias = self._add_bias(X)\n",
    "            num_samples, num_features = X_bias.shape\n",
    "            self.weights_ = np.zeros((num_features,1))\n",
    "\n",
    "            for _ in range (self.iterations):\n",
    "                gradient = -self._get_gradient(X_bias, y)\n",
    "                opts = {'maxiter': self.line_iterations}\n",
    "                res = minimize_scalar(self.objective_function,\n",
    "                                      bounds=(0,self.eta*10),\n",
    "                                      args=(X_bias, y, self.weights_, gradient, self.C),\n",
    "                                      method='bounded',\n",
    "                                      options=opts)\n",
    "                \n",
    "            eta = res.x\n",
    "            self.weights_ -= eta*gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97292144",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optimizing 2: Stoachastic Gradient Ascent\n",
    "\n",
    "class StochasticLogisticRegression(BinaryLogisticRegression):\n",
    "    def _get_gradient(self, X, y):\n",
    "        # Adjust batch size as needed, calculates gradient according to this batch size\n",
    "        batch_size = 16\n",
    "        idxs = np.random.choice(len(y), batch_size)\n",
    "\n",
    "        y_diff = y[idxs] - self.predict_proba(X[idxs], add_bias=False).ravel()\n",
    "        gradient= np.mean(X[idxs] * y_diff[:,np.newaxis], axis = 0)\n",
    "\n",
    "        gradient = gradient.reshape(self.weights_.shape)\n",
    "        if self.penalty == 'l1':\n",
    "            # Double check this, not sure\n",
    "            gradient[1:] += self.C * sum(abs(self.weights_[1:]))\n",
    "        elif self.penalty == 'l2':\n",
    "            # Double check this, not sure\n",
    "            gradient[1:] += self.C * sum(self.weights_[1:]**2)\n",
    "        elif self.penalty == 'both':\n",
    "            gradient[1:] += self.C * sum(self.weights_[1:]**2) + self.C * sum(abs(self.weights_[1:]))\n",
    "        elif self.penalty == 'none':\n",
    "            pass\n",
    "\n",
    "        # This might need to be negative?\n",
    "        return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85c91a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fmin_bfgs\n",
    "## Optimizing 3: Quasi-Newton Method (BFGS)\n",
    "\n",
    "class BFGSLogisticRegression(BinaryLogisticRegression):\n",
    "\n",
    "    @staticmethod\n",
    "    def objective_function(w, X, y, C):\n",
    "        gradient = expit(X @ w)\n",
    "        return -ma.sum(ma.log(g[y==1])-ma.sum(ma.log(1-g[y==0]))) + C*sum(w**2)\n",
    "    \n",
    "    @staticmethod\n",
    "    def objective_gradient(self, w, X, y, C):\n",
    "        gradient = expit(X @ w)\n",
    "        y_diff = y-gradient\n",
    "        gradient = np.mean(X * y_diff[:,np.newaxis], axis = 0)\n",
    "        gradient = gradient.reshape(w.shape)\n",
    "        if self.penalty == 'l1':\n",
    "            # Double check this, not sure\n",
    "            gradient[1:] += self.C * sum(abs(self.weights_[1:]))\n",
    "        elif self.penalty == 'l2':\n",
    "            # Double check this, not sure\n",
    "            gradient[1:] += self.C * sum(self.weights_[1:]**2)\n",
    "        elif self.penalty == 'both':\n",
    "            gradient[1:] += self.C * sum(self.weights_[1:]**2) + self.C * sum(abs(self.weights_[1:]))\n",
    "        elif self.penalty == 'none':\n",
    "            pass\n",
    "        return -gradient\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X_bias = self._add_bias(X)\n",
    "        num_samples, num_features = X_bias.shape\n",
    "\n",
    "        self.weights_ = fmin_bfgs(self.objective_function,\n",
    "                                  np.zeros((num_features,1)),\n",
    "                                  fprime=self.objective_gradient,\n",
    "                                  args=(X_bias, y, self.C),\n",
    "                                  gtol=1e-03,\n",
    "                                  maxiter=self.iterations,\n",
    "                                  disp=False)\n",
    "        self.weights_ = self.weights_.reshape((num_features,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e435ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regularized Logistic Regression using vectorized implementation\n",
    "class MultiClassLogisticRegression:\n",
    "    # Adjust default values for iterations and C as needed, temp default for solver is LineSearchLogisticRegression\n",
    "    # Penalty can be either 'l1' or 'l2' or 'both', default to 'l2' for now (these are passed to the solver)\n",
    "    def __init__(self, **kwds):\n",
    "        self.eta = kwds.get('eta', 0.01)  # The learning rate\n",
    "        self.iterations = kwds.get('iterations', 20)\n",
    "        self.line_iterations = kwds.get('line_iterations', 0.0)\n",
    "        self.C = kwds.get('C', 0.001)\n",
    "        self.penalty = kwds.get('penalty', 'l2')\n",
    "        self.solver = kwds.get('solver', LineSearchLogisticRegression)\n",
    "        self.classifiers_ = []\n",
    "\n",
    "    def __str__(self):\n",
    "        if(hasattr(self, 'weights_')):\n",
    "            return \"Multiclass Logistic Regression Object with coefficients:\\n\" + str(self.weights_)\n",
    "        return 'Multiclass Logistic Regression Object is untrained'\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.unique_classes_ = np.unique(y)\n",
    "        num_unique_classes = len(self.unique_classes_)\n",
    "        self.classifiers_ = []\n",
    "\n",
    "        for i, y_value in enumerate(self.unique_classes_):\n",
    "            # One vs All\n",
    "            y_binary = (y==y_value)\n",
    "            # Only pass line_iterations to solver if it is not 0.0\n",
    "            if self.line_iterations == 0.0:\n",
    "                lr = self.solver(eta=self.eta, iterations=self.iterations, C=self.C, penalty=self.penalty)\n",
    "            else:\n",
    "                lr = self.solver(eta=self.eta, iterations=self.iterations, line_iterations=self.line_iterations, C=self.C, penalty=self.penalty)\n",
    "            lr.fit(X, y_binary)\n",
    "            self.classifiers_.append(lr)\n",
    "        \n",
    "        self.weights_ = np.hstack([x.weights_ for x in self.classifiers_]).T\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        probabilities = []\n",
    "        for lr in self.classifiers_:\n",
    "            probabilities.append(lr.predict_proba(X))\n",
    "        return np.hstack(probabilities)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.unique_classes_[np.argmax(self.predict_proba(X), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457cfc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set X equal to the data in df, and y equal to the Genre column\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = df.drop(columns=['Genre'])\n",
    "y = df['Genre']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Need to address the categorical variables in the data, represent them as binary variables somehow\n",
    "\n",
    "# Extra parameter line_iterations only used for LineSearchLogisticRegression\n",
    "# mlr = MultiClassLogisticRegression(eta=.5, \n",
    "#                                    iterations=4, \n",
    "#                                    line_iterations=0.0,\n",
    "#                                    C=0.01, \n",
    "#                                    solver=LineSearchLogisticRegression, \n",
    "#                                    penalty='l2')\n",
    "\n",
    "# mlr.fit(X_train, y_train)\n",
    "# print(mlr)\n",
    "\n",
    "# print('Accuracy: ', accuracy_score(y_test, mlr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32cd98b",
   "metadata": {},
   "source": [
    "## 4. Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650c0df6",
   "metadata": {},
   "source": [
    "## 5. Exceptional Work (rename to what we actually end up doing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee83e623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
