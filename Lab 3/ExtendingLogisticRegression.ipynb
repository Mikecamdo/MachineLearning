{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d35a951",
   "metadata": {},
   "source": [
    "# Lab 3: Extending Logistic Regression\n",
    "## by Michael Doherty, Leilani Guzman, and Carson Pittman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9660f3bc",
   "metadata": {},
   "source": [
    "## 1. Business Understanding\n",
    "\n",
    "In 1633, the Japanese government, feeling threatened by Spanish and Portugese influence within their country, banned foreign goods as part of their isolationist foreign policy (called [Sakoku](https://en.wikipedia.org/wiki/Sakoku)). As part of this ban, European playing cards were forbidden, so Japanese playing cards, called [hanafuda](https://lammuseum.wfu.edu/2021/12/japanese-hanafuda-cards/), were developed; however, hanafuda struggled to gain popularity among the Japanese populace. Centuries later, on November 22, 1859 in Kyoto, Japan, a man named Fusajiro Yamauchi was born. An aspiring artist and entrepreneur, Yamauchi saw an opportunity with hanafuda, so in 1889 he opened a shop to sell his own handcrafted cards. What was the name of that shop? [Nintendo Koppai](https://www.lifewire.com/fusajiro-yamauchi-founder-of-nintendo-729584) (which was later shortened to just Nintendo).\n",
    "\n",
    "While Fusajiro Yamauchi would never know it, his card company would eventually become one of the biggest video game companies in the world. Since the mid-twentieth century, advancements in technology have propelled video games to become a multi-billion dollar industry. Yet, not all video games are made equal; from sports games like the [FIFA series](https://en.wikipedia.org/wiki/FIFA_(video_game_series)) to puzzle games like [Tetris](https://en.wikipedia.org/wiki/Tetris), there are several genres that a video game can belong to.\n",
    "\n",
    "The dataset we've selected, titled \"Global Video Game Sales\", was created to analyze how a video game's genre relates to the platform it was released on, its publisher, and its sales (both globally and in various regions). The dataset consists of 16,600 instances with 11 multivariate attributes, comprised of numeric and categorical data types.\n",
    "\n",
    "Ultimately, the prediction task for this dataset is to determine what a video game's genre is. Who might be interested in this research? For starters, video game companies may be interested to see which video game genre has the best sales. They may also find that certain genres are more popular in some markets than others (such as puzzle games being popular in Japan and sports games being popular in Europe). This information can help inform their strategies on what types of games they should make and where they should focus their marketing efforts. The prediction model created would be mostly used for offline analysis (as there aren't enough video games being created all the time that would justify having a deployed model).\n",
    "\n",
    "So what does a good prediction algorithm for this dataset look like? There are several factors that need to be considered:\n",
    "- **Finding Useful Trends**: One of the most important factors for the prediction algorithm is being able to find clear trends relating to a video game's genre. For example, finding that Nintendo games sell best in Japan, or that the most profitable video game genre is Shooter games, would be useful information that video game companies could use to make decisions regarding future video games, where to market their products more, etc.\n",
    "- **Accuracy**: How accurate the prediction algorithm is at classifying video game genres is one of the most important aspects. The more accurate the prediction algorithm is, the more reliable the trends will be that we derive from the prediction algorithm. Thus, we want the accuracy to be as high as possible; at minimum, it should be higher than 50%, and ideally it would have  an accuracy greater than 90%.  \n",
    "\n",
    "Thus, there are several aspects that need to be considered when trying to create a reliable prediction model. The data derived from the model should help companies make informed decisions on what types of video games to make, where they should advertise certain types of games more heavily, Ultimately, any good prediction model would need to prove useful to video game companies by providing useful insights that can help them increase their profits.\n",
    "\n",
    "Link to the dataset: https://www.kaggle.com/datasets/thedevastator/global-video-game-sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e3860f",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cd39165",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16598 entries, 0 to 16597\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Rank          16598 non-null  int64  \n",
      " 1   Name          16598 non-null  object \n",
      " 2   Platform      16598 non-null  object \n",
      " 3   Year          16327 non-null  float64\n",
      " 4   Genre         16598 non-null  object \n",
      " 5   Publisher     16540 non-null  object \n",
      " 6   NA_Sales      16598 non-null  float64\n",
      " 7   EU_Sales      16598 non-null  float64\n",
      " 8   JP_Sales      16598 non-null  float64\n",
      " 9   Other_Sales   16598 non-null  float64\n",
      " 10  Global_Sales  16598 non-null  float64\n",
      "dtypes: float64(6), int64(1), object(4)\n",
      "memory usage: 1.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>180</td>\n",
       "      <td>Madden NFL 2004</td>\n",
       "      <td>PS2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Electronic Arts</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.71</td>\n",
       "      <td>5.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>378</td>\n",
       "      <td>FIFA Soccer 2004</td>\n",
       "      <td>PS2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Electronic Arts</td>\n",
       "      <td>0.59</td>\n",
       "      <td>2.36</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.51</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>432</td>\n",
       "      <td>LEGO Batman: The Videogame</td>\n",
       "      <td>Wii</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Action</td>\n",
       "      <td>Warner Bros. Interactive Entertainment</td>\n",
       "      <td>1.86</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>471</td>\n",
       "      <td>wwe Smackdown vs. Raw 2006</td>\n",
       "      <td>PS2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fighting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.41</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>608</td>\n",
       "      <td>Space Invaders</td>\n",
       "      <td>2600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shooter</td>\n",
       "      <td>Atari</td>\n",
       "      <td>2.36</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16307</th>\n",
       "      <td>16310</td>\n",
       "      <td>Freaky Flyers</td>\n",
       "      <td>GC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16327</th>\n",
       "      <td>16330</td>\n",
       "      <td>Inversion</td>\n",
       "      <td>PC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shooter</td>\n",
       "      <td>Namco Bandai Games</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16366</th>\n",
       "      <td>16369</td>\n",
       "      <td>Hakuouki: Shinsengumi Kitan</td>\n",
       "      <td>PS3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16427</th>\n",
       "      <td>16430</td>\n",
       "      <td>Virtua Quest</td>\n",
       "      <td>GC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16493</th>\n",
       "      <td>16496</td>\n",
       "      <td>The Smurfs</td>\n",
       "      <td>3DS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Action</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rank                         Name Platform  Year         Genre  \\\n",
       "179      180              Madden NFL 2004      PS2   NaN        Sports   \n",
       "377      378             FIFA Soccer 2004      PS2   NaN        Sports   \n",
       "431      432   LEGO Batman: The Videogame      Wii   NaN        Action   \n",
       "470      471   wwe Smackdown vs. Raw 2006      PS2   NaN      Fighting   \n",
       "607      608               Space Invaders     2600   NaN       Shooter   \n",
       "...      ...                          ...      ...   ...           ...   \n",
       "16307  16310                Freaky Flyers       GC   NaN        Racing   \n",
       "16327  16330                    Inversion       PC   NaN       Shooter   \n",
       "16366  16369  Hakuouki: Shinsengumi Kitan      PS3   NaN     Adventure   \n",
       "16427  16430                 Virtua Quest       GC   NaN  Role-Playing   \n",
       "16493  16496                   The Smurfs      3DS   NaN        Action   \n",
       "\n",
       "                                    Publisher  NA_Sales  EU_Sales  JP_Sales  \\\n",
       "179                           Electronic Arts      4.26      0.26      0.01   \n",
       "377                           Electronic Arts      0.59      2.36      0.04   \n",
       "431    Warner Bros. Interactive Entertainment      1.86      1.02      0.00   \n",
       "470                                       NaN      1.57      1.02      0.00   \n",
       "607                                     Atari      2.36      0.14      0.00   \n",
       "...                                       ...       ...       ...       ...   \n",
       "16307                                 Unknown      0.01      0.00      0.00   \n",
       "16327                      Namco Bandai Games      0.01      0.00      0.00   \n",
       "16366                                 Unknown      0.01      0.00      0.00   \n",
       "16427                                 Unknown      0.01      0.00      0.00   \n",
       "16493                                 Unknown      0.00      0.01      0.00   \n",
       "\n",
       "       Other_Sales  Global_Sales  \n",
       "179           0.71          5.23  \n",
       "377           0.51          3.49  \n",
       "431           0.29          3.17  \n",
       "470           0.41          3.00  \n",
       "607           0.03          2.53  \n",
       "...            ...           ...  \n",
       "16307         0.00          0.01  \n",
       "16327         0.00          0.01  \n",
       "16366         0.00          0.01  \n",
       "16427         0.00          0.01  \n",
       "16493         0.00          0.01  \n",
       "\n",
       "[271 rows x 11 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/vgsales.csv\")\n",
    "\n",
    "df.info()\n",
    "df[df[\"Year\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e634c503",
   "metadata": {},
   "source": [
    "As shown above, there is missing data for both the <code>Year</code> and <code>Publisher</code> attributes. The dataset is currently split up by <code>Platform</code> (meaning that Grand Theft Auto V on the Xbox 360 and Grand Theft Auto V on the PlayStation 4 are two separate rows, each with their own sales data, even though they are the same game). Some of the missing data can thus be found by looking at other rows about the same video game. For example, as seen above, Madden NFL 2004 on the PlayStation 2 is missing a <code>Year</code> attribute, but by looking at other rows for Madden NFL 2004 (such as the row for its release on the Xbox), we can see that the game released in 2003.\n",
    "\n",
    "Since most video games are released on a multitude of platforms, and the sales data for this dataset is split up by platform, we decided to aggregate the data and drop the <code>Platform</code> attribute. In doing so, we can fill in some of the missing data and reduce the size of our dataset. We also believe that total sales data (regardless of platform) is much more important to determining a video game's genre than the platform the video game released on (as most games released on Xbox consoles are also released on PlayStation consoles, some games might have lower sales on a certain console because a newer console had recently been released by that point, etc.). Because of this aggregation, the <code>Rank</code> attribute is also no longer relevant (as it is based on the total sales data for each video game, which we are modifying when we aggregate the data, meaning <code>Rank</code> is no longer accurate). Thus, we will aggregate the data and drop the <code>Platform</code> and <code>Rank</code> columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "797142e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11493 entries, '98 Koshien to ¡Shin Chan Flipa en colores!\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Name          11493 non-null  object \n",
      " 1   Year          11360 non-null  float64\n",
      " 2   Genre         11493 non-null  object \n",
      " 3   Publisher     11442 non-null  object \n",
      " 4   NA_Sales      11493 non-null  float64\n",
      " 5   EU_Sales      11493 non-null  float64\n",
      " 6   JP_Sales      11493 non-null  float64\n",
      " 7   Other_Sales   11493 non-null  float64\n",
      " 8   Global_Sales  11493 non-null  float64\n",
      "dtypes: float64(6), object(3)\n",
      "memory usage: 897.9+ KB\n"
     ]
    }
   ],
   "source": [
    "#Data Cleaning with Aggregation\n",
    "\n",
    "df = df.groupby(\"Name\").aggregate({'Rank': 'first', 'Platform': 'first', 'Name': 'first', 'Year': 'first', 'Genre': 'first', 'Publisher': 'last', 'NA_Sales': 'sum', 'EU_Sales': 'sum', 'JP_Sales': 'sum', 'Other_Sales': 'sum', 'Global_Sales': 'sum' })\n",
    "del df[\"Platform\"]\n",
    "del df[\"Rank\"]\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59160400",
   "metadata": {},
   "source": [
    "Since there is still some missing data, we decided to drop these rows, as after aggregating the data, any video games missing their <code>Publisher</code> or <code>Year</code> are probably fairly obscure games and could be regarded as outliers; additionally, we have plenty of data to work with, even after dropping the rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16f1238e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11325 entries, '98 Koshien to ¡Shin Chan Flipa en colores!\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Name          11325 non-null  object \n",
      " 1   Year          11325 non-null  float64\n",
      " 2   Genre         11325 non-null  object \n",
      " 3   Publisher     11325 non-null  object \n",
      " 4   NA_Sales      11325 non-null  float64\n",
      " 5   EU_Sales      11325 non-null  float64\n",
      " 6   JP_Sales      11325 non-null  float64\n",
      " 7   Other_Sales   11325 non-null  float64\n",
      " 8   Global_Sales  11325 non-null  float64\n",
      "dtypes: float64(6), object(3)\n",
      "memory usage: 884.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#Removing Null Values\n",
    "\n",
    "df = df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d74b97b",
   "metadata": {},
   "source": [
    "The data types above are accurate except for year, which is stored as a float. Since this set only has integer years, we change the years to be an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "394693b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'98 Koshien</th>\n",
       "      <td>'98 Koshien</td>\n",
       "      <td>1998</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Magical Company</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.hack//G.U. Vol.1//Rebirth</th>\n",
       "      <td>.hack//G.U. Vol.1//Rebirth</td>\n",
       "      <td>2006</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Namco Bandai Games</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.hack//G.U. Vol.2//Reminisce</th>\n",
       "      <td>.hack//G.U. Vol.2//Reminisce</td>\n",
       "      <td>2006</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Namco Bandai Games</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.hack//G.U. Vol.2//Reminisce (jp sales)</th>\n",
       "      <td>.hack//G.U. Vol.2//Reminisce (jp sales)</td>\n",
       "      <td>2006</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Namco Bandai Games</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.hack//G.U. Vol.3//Redemption</th>\n",
       "      <td>.hack//G.U. Vol.3//Redemption</td>\n",
       "      <td>2007</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Namco Bandai Games</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Name  \\\n",
       "Name                                                                               \n",
       "'98 Koshien                                                          '98 Koshien   \n",
       ".hack//G.U. Vol.1//Rebirth                            .hack//G.U. Vol.1//Rebirth   \n",
       ".hack//G.U. Vol.2//Reminisce                        .hack//G.U. Vol.2//Reminisce   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)  .hack//G.U. Vol.2//Reminisce (jp sales)   \n",
       ".hack//G.U. Vol.3//Redemption                      .hack//G.U. Vol.3//Redemption   \n",
       "\n",
       "                                         Year         Genre  \\\n",
       "Name                                                          \n",
       "'98 Koshien                              1998        Sports   \n",
       ".hack//G.U. Vol.1//Rebirth               2006  Role-Playing   \n",
       ".hack//G.U. Vol.2//Reminisce             2006  Role-Playing   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)  2006  Role-Playing   \n",
       ".hack//G.U. Vol.3//Redemption            2007  Role-Playing   \n",
       "\n",
       "                                                  Publisher  NA_Sales  \\\n",
       "Name                                                                    \n",
       "'98 Koshien                                 Magical Company      0.15   \n",
       ".hack//G.U. Vol.1//Rebirth               Namco Bandai Games      0.00   \n",
       ".hack//G.U. Vol.2//Reminisce             Namco Bandai Games      0.11   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)  Namco Bandai Games      0.00   \n",
       ".hack//G.U. Vol.3//Redemption            Namco Bandai Games      0.00   \n",
       "\n",
       "                                         EU_Sales  JP_Sales  Other_Sales  \\\n",
       "Name                                                                       \n",
       "'98 Koshien                                  0.10      0.12         0.03   \n",
       ".hack//G.U. Vol.1//Rebirth                   0.00      0.17         0.00   \n",
       ".hack//G.U. Vol.2//Reminisce                 0.09      0.00         0.03   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)      0.00      0.16         0.00   \n",
       ".hack//G.U. Vol.3//Redemption                0.00      0.17         0.00   \n",
       "\n",
       "                                         Global_Sales  \n",
       "Name                                                   \n",
       "'98 Koshien                                      0.41  \n",
       ".hack//G.U. Vol.1//Rebirth                       0.17  \n",
       ".hack//G.U. Vol.2//Reminisce                     0.23  \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)          0.16  \n",
       ".hack//G.U. Vol.3//Redemption                    0.17  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.astype({'Year': 'int'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770d1dfd",
   "metadata": {},
   "source": [
    "Next, we need to one-hot encode our categorical data so it can be used in our Logistic Regression  algorithms. Thus, we will one-hot encode the <code>Publisher</code> attributes of our data. This allows for the algorithm to use it as numeric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "160774d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Publisher_10TACLE Studios</th>\n",
       "      <th>Publisher_1C Company</th>\n",
       "      <th>...</th>\n",
       "      <th>Publisher_Zoo Games</th>\n",
       "      <th>Publisher_Zushi Games</th>\n",
       "      <th>Publisher_bitComposer Games</th>\n",
       "      <th>Publisher_dramatic create</th>\n",
       "      <th>Publisher_fonfun</th>\n",
       "      <th>Publisher_iWin</th>\n",
       "      <th>Publisher_id Software</th>\n",
       "      <th>Publisher_imageepoch Inc.</th>\n",
       "      <th>Publisher_mixi, Inc</th>\n",
       "      <th>Publisher_responDESIGN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'98 Koshien</th>\n",
       "      <td>'98 Koshien</td>\n",
       "      <td>1998</td>\n",
       "      <td>Sports</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.hack//G.U. Vol.1//Rebirth</th>\n",
       "      <td>.hack//G.U. Vol.1//Rebirth</td>\n",
       "      <td>2006</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.hack//G.U. Vol.2//Reminisce</th>\n",
       "      <td>.hack//G.U. Vol.2//Reminisce</td>\n",
       "      <td>2006</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.hack//G.U. Vol.2//Reminisce (jp sales)</th>\n",
       "      <td>.hack//G.U. Vol.2//Reminisce (jp sales)</td>\n",
       "      <td>2006</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.hack//G.U. Vol.3//Redemption</th>\n",
       "      <td>.hack//G.U. Vol.3//Redemption</td>\n",
       "      <td>2007</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 574 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Name  \\\n",
       "Name                                                                               \n",
       "'98 Koshien                                                          '98 Koshien   \n",
       ".hack//G.U. Vol.1//Rebirth                            .hack//G.U. Vol.1//Rebirth   \n",
       ".hack//G.U. Vol.2//Reminisce                        .hack//G.U. Vol.2//Reminisce   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)  .hack//G.U. Vol.2//Reminisce (jp sales)   \n",
       ".hack//G.U. Vol.3//Redemption                      .hack//G.U. Vol.3//Redemption   \n",
       "\n",
       "                                         Year         Genre  NA_Sales  \\\n",
       "Name                                                                    \n",
       "'98 Koshien                              1998        Sports      0.15   \n",
       ".hack//G.U. Vol.1//Rebirth               2006  Role-Playing      0.00   \n",
       ".hack//G.U. Vol.2//Reminisce             2006  Role-Playing      0.11   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)  2006  Role-Playing      0.00   \n",
       ".hack//G.U. Vol.3//Redemption            2007  Role-Playing      0.00   \n",
       "\n",
       "                                         EU_Sales  JP_Sales  Other_Sales  \\\n",
       "Name                                                                       \n",
       "'98 Koshien                                  0.10      0.12         0.03   \n",
       ".hack//G.U. Vol.1//Rebirth                   0.00      0.17         0.00   \n",
       ".hack//G.U. Vol.2//Reminisce                 0.09      0.00         0.03   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)      0.00      0.16         0.00   \n",
       ".hack//G.U. Vol.3//Redemption                0.00      0.17         0.00   \n",
       "\n",
       "                                         Global_Sales  \\\n",
       "Name                                                    \n",
       "'98 Koshien                                      0.41   \n",
       ".hack//G.U. Vol.1//Rebirth                       0.17   \n",
       ".hack//G.U. Vol.2//Reminisce                     0.23   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)          0.16   \n",
       ".hack//G.U. Vol.3//Redemption                    0.17   \n",
       "\n",
       "                                         Publisher_10TACLE Studios  \\\n",
       "Name                                                                 \n",
       "'98 Koshien                                                      0   \n",
       ".hack//G.U. Vol.1//Rebirth                                       0   \n",
       ".hack//G.U. Vol.2//Reminisce                                     0   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)                          0   \n",
       ".hack//G.U. Vol.3//Redemption                                    0   \n",
       "\n",
       "                                         Publisher_1C Company  ...  \\\n",
       "Name                                                           ...   \n",
       "'98 Koshien                                                 0  ...   \n",
       ".hack//G.U. Vol.1//Rebirth                                  0  ...   \n",
       ".hack//G.U. Vol.2//Reminisce                                0  ...   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)                     0  ...   \n",
       ".hack//G.U. Vol.3//Redemption                               0  ...   \n",
       "\n",
       "                                         Publisher_Zoo Games  \\\n",
       "Name                                                           \n",
       "'98 Koshien                                                0   \n",
       ".hack//G.U. Vol.1//Rebirth                                 0   \n",
       ".hack//G.U. Vol.2//Reminisce                               0   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)                    0   \n",
       ".hack//G.U. Vol.3//Redemption                              0   \n",
       "\n",
       "                                         Publisher_Zushi Games  \\\n",
       "Name                                                             \n",
       "'98 Koshien                                                  0   \n",
       ".hack//G.U. Vol.1//Rebirth                                   0   \n",
       ".hack//G.U. Vol.2//Reminisce                                 0   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)                      0   \n",
       ".hack//G.U. Vol.3//Redemption                                0   \n",
       "\n",
       "                                         Publisher_bitComposer Games  \\\n",
       "Name                                                                   \n",
       "'98 Koshien                                                        0   \n",
       ".hack//G.U. Vol.1//Rebirth                                         0   \n",
       ".hack//G.U. Vol.2//Reminisce                                       0   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)                            0   \n",
       ".hack//G.U. Vol.3//Redemption                                      0   \n",
       "\n",
       "                                         Publisher_dramatic create  \\\n",
       "Name                                                                 \n",
       "'98 Koshien                                                      0   \n",
       ".hack//G.U. Vol.1//Rebirth                                       0   \n",
       ".hack//G.U. Vol.2//Reminisce                                     0   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)                          0   \n",
       ".hack//G.U. Vol.3//Redemption                                    0   \n",
       "\n",
       "                                         Publisher_fonfun  Publisher_iWin  \\\n",
       "Name                                                                        \n",
       "'98 Koshien                                             0               0   \n",
       ".hack//G.U. Vol.1//Rebirth                              0               0   \n",
       ".hack//G.U. Vol.2//Reminisce                            0               0   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)                 0               0   \n",
       ".hack//G.U. Vol.3//Redemption                           0               0   \n",
       "\n",
       "                                         Publisher_id Software  \\\n",
       "Name                                                             \n",
       "'98 Koshien                                                  0   \n",
       ".hack//G.U. Vol.1//Rebirth                                   0   \n",
       ".hack//G.U. Vol.2//Reminisce                                 0   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)                      0   \n",
       ".hack//G.U. Vol.3//Redemption                                0   \n",
       "\n",
       "                                         Publisher_imageepoch Inc.  \\\n",
       "Name                                                                 \n",
       "'98 Koshien                                                      0   \n",
       ".hack//G.U. Vol.1//Rebirth                                       0   \n",
       ".hack//G.U. Vol.2//Reminisce                                     0   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)                          0   \n",
       ".hack//G.U. Vol.3//Redemption                                    0   \n",
       "\n",
       "                                         Publisher_mixi, Inc  \\\n",
       "Name                                                           \n",
       "'98 Koshien                                                0   \n",
       ".hack//G.U. Vol.1//Rebirth                                 0   \n",
       ".hack//G.U. Vol.2//Reminisce                               0   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)                    0   \n",
       ".hack//G.U. Vol.3//Redemption                              0   \n",
       "\n",
       "                                         Publisher_responDESIGN  \n",
       "Name                                                             \n",
       "'98 Koshien                                                   0  \n",
       ".hack//G.U. Vol.1//Rebirth                                    0  \n",
       ".hack//G.U. Vol.2//Reminisce                                  0  \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)                       0  \n",
       ".hack//G.U. Vol.3//Redemption                                 0  \n",
       "\n",
       "[5 rows x 574 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One Hot Encoding\n",
    "\n",
    "df_onehot = pd.get_dummies(df, columns=['Publisher'])\n",
    "\n",
    "df_onehot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3f0aef",
   "metadata": {},
   "source": [
    "Finally, We scaled our numeric data to prevent the larger values from affecting the model as much as the smaller values. Scaling will help to prevent the model from being biased towards certain attributes over others.\n",
    "\n",
    "Our final dataset is described below. It shows how there is no missing data because the columns all have the same count. It also shows the mean, standard deviation, min, max, and quartile information. This table shows how much larger the year values are to all other values in this dataset. The other numbers are closer in scale, but should still be scaled to ensure there is no bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "512276b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Publisher_10TACLE Studios</th>\n",
       "      <th>Publisher_1C Company</th>\n",
       "      <th>Publisher_20th Century Fox Video Games</th>\n",
       "      <th>Publisher_2D Boy</th>\n",
       "      <th>...</th>\n",
       "      <th>Publisher_Zoo Games</th>\n",
       "      <th>Publisher_Zushi Games</th>\n",
       "      <th>Publisher_bitComposer Games</th>\n",
       "      <th>Publisher_dramatic create</th>\n",
       "      <th>Publisher_fonfun</th>\n",
       "      <th>Publisher_iWin</th>\n",
       "      <th>Publisher_id Software</th>\n",
       "      <th>Publisher_imageepoch Inc.</th>\n",
       "      <th>Publisher_mixi, Inc</th>\n",
       "      <th>Publisher_responDESIGN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2005.633819</td>\n",
       "      <td>0.384970</td>\n",
       "      <td>0.213965</td>\n",
       "      <td>0.113571</td>\n",
       "      <td>0.070151</td>\n",
       "      <td>0.783050</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.099033</td>\n",
       "      <td>1.179826</td>\n",
       "      <td>0.767471</td>\n",
       "      <td>0.389027</td>\n",
       "      <td>0.275877</td>\n",
       "      <td>2.255285</td>\n",
       "      <td>0.016274</td>\n",
       "      <td>0.016274</td>\n",
       "      <td>0.021008</td>\n",
       "      <td>0.009397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049664</td>\n",
       "      <td>0.033863</td>\n",
       "      <td>0.016274</td>\n",
       "      <td>0.021008</td>\n",
       "      <td>0.009397</td>\n",
       "      <td>0.009397</td>\n",
       "      <td>0.009397</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.009397</td>\n",
       "      <td>0.009397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1980.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2002.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2007.000000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2010.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2020.000000</td>\n",
       "      <td>41.490000</td>\n",
       "      <td>29.020000</td>\n",
       "      <td>10.220000</td>\n",
       "      <td>10.720000</td>\n",
       "      <td>82.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 572 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Year      NA_Sales      EU_Sales      JP_Sales   Other_Sales  \\\n",
       "count  11325.000000  11325.000000  11325.000000  11325.000000  11325.000000   \n",
       "mean    2005.633819      0.384970      0.213965      0.113571      0.070151   \n",
       "std        6.099033      1.179826      0.767471      0.389027      0.275877   \n",
       "min     1980.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%     2002.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%     2007.000000      0.070000      0.020000      0.000000      0.010000   \n",
       "75%     2010.000000      0.300000      0.130000      0.070000      0.040000   \n",
       "max     2020.000000     41.490000     29.020000     10.220000     10.720000   \n",
       "\n",
       "       Global_Sales  Publisher_10TACLE Studios  Publisher_1C Company  \\\n",
       "count  11325.000000               11325.000000          11325.000000   \n",
       "mean       0.783050                   0.000265              0.000265   \n",
       "std        2.255285                   0.016274              0.016274   \n",
       "min        0.010000                   0.000000              0.000000   \n",
       "25%        0.060000                   0.000000              0.000000   \n",
       "50%        0.190000                   0.000000              0.000000   \n",
       "75%        0.620000                   0.000000              0.000000   \n",
       "max       82.740000                   1.000000              1.000000   \n",
       "\n",
       "       Publisher_20th Century Fox Video Games  Publisher_2D Boy  ...  \\\n",
       "count                            11325.000000      11325.000000  ...   \n",
       "mean                                 0.000442          0.000088  ...   \n",
       "std                                  0.021008          0.009397  ...   \n",
       "min                                  0.000000          0.000000  ...   \n",
       "25%                                  0.000000          0.000000  ...   \n",
       "50%                                  0.000000          0.000000  ...   \n",
       "75%                                  0.000000          0.000000  ...   \n",
       "max                                  1.000000          1.000000  ...   \n",
       "\n",
       "       Publisher_Zoo Games  Publisher_Zushi Games  \\\n",
       "count         11325.000000           11325.000000   \n",
       "mean              0.002472               0.001148   \n",
       "std               0.049664               0.033863   \n",
       "min               0.000000               0.000000   \n",
       "25%               0.000000               0.000000   \n",
       "50%               0.000000               0.000000   \n",
       "75%               0.000000               0.000000   \n",
       "max               1.000000               1.000000   \n",
       "\n",
       "       Publisher_bitComposer Games  Publisher_dramatic create  \\\n",
       "count                 11325.000000               11325.000000   \n",
       "mean                      0.000265                   0.000442   \n",
       "std                       0.016274                   0.021008   \n",
       "min                       0.000000                   0.000000   \n",
       "25%                       0.000000                   0.000000   \n",
       "50%                       0.000000                   0.000000   \n",
       "75%                       0.000000                   0.000000   \n",
       "max                       1.000000                   1.000000   \n",
       "\n",
       "       Publisher_fonfun  Publisher_iWin  Publisher_id Software  \\\n",
       "count      11325.000000    11325.000000           11325.000000   \n",
       "mean           0.000088        0.000088               0.000088   \n",
       "std            0.009397        0.009397               0.009397   \n",
       "min            0.000000        0.000000               0.000000   \n",
       "25%            0.000000        0.000000               0.000000   \n",
       "50%            0.000000        0.000000               0.000000   \n",
       "75%            0.000000        0.000000               0.000000   \n",
       "max            1.000000        1.000000               1.000000   \n",
       "\n",
       "       Publisher_imageepoch Inc.  Publisher_mixi, Inc  Publisher_responDESIGN  \n",
       "count               11325.000000         11325.000000            11325.000000  \n",
       "mean                    0.000177             0.000088                0.000088  \n",
       "std                     0.013289             0.009397                0.009397  \n",
       "min                     0.000000             0.000000                0.000000  \n",
       "25%                     0.000000             0.000000                0.000000  \n",
       "50%                     0.000000             0.000000                0.000000  \n",
       "75%                     0.000000             0.000000                0.000000  \n",
       "max                     1.000000             1.000000                1.000000  \n",
       "\n",
       "[8 rows x 572 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_onehot.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81f2eed",
   "metadata": {},
   "source": [
    "The values in the dataset are now scaled and all have a mean of zero and a standard deviation of 1. After the scaling, this is the data we will use in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84854a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Publisher_10TACLE Studios</th>\n",
       "      <th>Publisher_1C Company</th>\n",
       "      <th>...</th>\n",
       "      <th>Publisher_Zoo Games</th>\n",
       "      <th>Publisher_Zushi Games</th>\n",
       "      <th>Publisher_bitComposer Games</th>\n",
       "      <th>Publisher_dramatic create</th>\n",
       "      <th>Publisher_fonfun</th>\n",
       "      <th>Publisher_iWin</th>\n",
       "      <th>Publisher_id Software</th>\n",
       "      <th>Publisher_imageepoch Inc.</th>\n",
       "      <th>Publisher_mixi, Inc</th>\n",
       "      <th>Publisher_responDESIGN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'98 Koshien</th>\n",
       "      <td>'98 Koshien</td>\n",
       "      <td>-1.251699</td>\n",
       "      <td>Sports</td>\n",
       "      <td>-0.199166</td>\n",
       "      <td>-0.148500</td>\n",
       "      <td>0.016527</td>\n",
       "      <td>-0.145546</td>\n",
       "      <td>-0.165419</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.hack//G.U. Vol.1//Rebirth</th>\n",
       "      <td>.hack//G.U. Vol.1//Rebirth</td>\n",
       "      <td>0.060042</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>-0.326309</td>\n",
       "      <td>-0.278804</td>\n",
       "      <td>0.145058</td>\n",
       "      <td>-0.254295</td>\n",
       "      <td>-0.271840</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.hack//G.U. Vol.2//Reminisce</th>\n",
       "      <td>.hack//G.U. Vol.2//Reminisce</td>\n",
       "      <td>0.060042</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>-0.233070</td>\n",
       "      <td>-0.161531</td>\n",
       "      <td>-0.291949</td>\n",
       "      <td>-0.145546</td>\n",
       "      <td>-0.245235</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.hack//G.U. Vol.2//Reminisce (jp sales)</th>\n",
       "      <td>.hack//G.U. Vol.2//Reminisce (jp sales)</td>\n",
       "      <td>0.060042</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>-0.326309</td>\n",
       "      <td>-0.278804</td>\n",
       "      <td>0.119352</td>\n",
       "      <td>-0.254295</td>\n",
       "      <td>-0.276274</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.hack//G.U. Vol.3//Redemption</th>\n",
       "      <td>.hack//G.U. Vol.3//Redemption</td>\n",
       "      <td>0.224010</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>-0.326309</td>\n",
       "      <td>-0.278804</td>\n",
       "      <td>0.145058</td>\n",
       "      <td>-0.254295</td>\n",
       "      <td>-0.271840</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 574 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Name  \\\n",
       "Name                                                                               \n",
       "'98 Koshien                                                          '98 Koshien   \n",
       ".hack//G.U. Vol.1//Rebirth                            .hack//G.U. Vol.1//Rebirth   \n",
       ".hack//G.U. Vol.2//Reminisce                        .hack//G.U. Vol.2//Reminisce   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)  .hack//G.U. Vol.2//Reminisce (jp sales)   \n",
       ".hack//G.U. Vol.3//Redemption                      .hack//G.U. Vol.3//Redemption   \n",
       "\n",
       "                                             Year         Genre  NA_Sales  \\\n",
       "Name                                                                        \n",
       "'98 Koshien                             -1.251699        Sports -0.199166   \n",
       ".hack//G.U. Vol.1//Rebirth               0.060042  Role-Playing -0.326309   \n",
       ".hack//G.U. Vol.2//Reminisce             0.060042  Role-Playing -0.233070   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)  0.060042  Role-Playing -0.326309   \n",
       ".hack//G.U. Vol.3//Redemption            0.224010  Role-Playing -0.326309   \n",
       "\n",
       "                                         EU_Sales  JP_Sales  Other_Sales  \\\n",
       "Name                                                                       \n",
       "'98 Koshien                             -0.148500  0.016527    -0.145546   \n",
       ".hack//G.U. Vol.1//Rebirth              -0.278804  0.145058    -0.254295   \n",
       ".hack//G.U. Vol.2//Reminisce            -0.161531 -0.291949    -0.145546   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales) -0.278804  0.119352    -0.254295   \n",
       ".hack//G.U. Vol.3//Redemption           -0.278804  0.145058    -0.254295   \n",
       "\n",
       "                                         Global_Sales  \\\n",
       "Name                                                    \n",
       "'98 Koshien                                 -0.165419   \n",
       ".hack//G.U. Vol.1//Rebirth                  -0.271840   \n",
       ".hack//G.U. Vol.2//Reminisce                -0.245235   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)     -0.276274   \n",
       ".hack//G.U. Vol.3//Redemption               -0.271840   \n",
       "\n",
       "                                         Publisher_10TACLE Studios  \\\n",
       "Name                                                                 \n",
       "'98 Koshien                                                      0   \n",
       ".hack//G.U. Vol.1//Rebirth                                       0   \n",
       ".hack//G.U. Vol.2//Reminisce                                     0   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)                          0   \n",
       ".hack//G.U. Vol.3//Redemption                                    0   \n",
       "\n",
       "                                         Publisher_1C Company  ...  \\\n",
       "Name                                                           ...   \n",
       "'98 Koshien                                                 0  ...   \n",
       ".hack//G.U. Vol.1//Rebirth                                  0  ...   \n",
       ".hack//G.U. Vol.2//Reminisce                                0  ...   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)                     0  ...   \n",
       ".hack//G.U. Vol.3//Redemption                               0  ...   \n",
       "\n",
       "                                         Publisher_Zoo Games  \\\n",
       "Name                                                           \n",
       "'98 Koshien                                                0   \n",
       ".hack//G.U. Vol.1//Rebirth                                 0   \n",
       ".hack//G.U. Vol.2//Reminisce                               0   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)                    0   \n",
       ".hack//G.U. Vol.3//Redemption                              0   \n",
       "\n",
       "                                         Publisher_Zushi Games  \\\n",
       "Name                                                             \n",
       "'98 Koshien                                                  0   \n",
       ".hack//G.U. Vol.1//Rebirth                                   0   \n",
       ".hack//G.U. Vol.2//Reminisce                                 0   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)                      0   \n",
       ".hack//G.U. Vol.3//Redemption                                0   \n",
       "\n",
       "                                         Publisher_bitComposer Games  \\\n",
       "Name                                                                   \n",
       "'98 Koshien                                                        0   \n",
       ".hack//G.U. Vol.1//Rebirth                                         0   \n",
       ".hack//G.U. Vol.2//Reminisce                                       0   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)                            0   \n",
       ".hack//G.U. Vol.3//Redemption                                      0   \n",
       "\n",
       "                                         Publisher_dramatic create  \\\n",
       "Name                                                                 \n",
       "'98 Koshien                                                      0   \n",
       ".hack//G.U. Vol.1//Rebirth                                       0   \n",
       ".hack//G.U. Vol.2//Reminisce                                     0   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)                          0   \n",
       ".hack//G.U. Vol.3//Redemption                                    0   \n",
       "\n",
       "                                         Publisher_fonfun  Publisher_iWin  \\\n",
       "Name                                                                        \n",
       "'98 Koshien                                             0               0   \n",
       ".hack//G.U. Vol.1//Rebirth                              0               0   \n",
       ".hack//G.U. Vol.2//Reminisce                            0               0   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)                 0               0   \n",
       ".hack//G.U. Vol.3//Redemption                           0               0   \n",
       "\n",
       "                                         Publisher_id Software  \\\n",
       "Name                                                             \n",
       "'98 Koshien                                                  0   \n",
       ".hack//G.U. Vol.1//Rebirth                                   0   \n",
       ".hack//G.U. Vol.2//Reminisce                                 0   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)                      0   \n",
       ".hack//G.U. Vol.3//Redemption                                0   \n",
       "\n",
       "                                         Publisher_imageepoch Inc.  \\\n",
       "Name                                                                 \n",
       "'98 Koshien                                                      0   \n",
       ".hack//G.U. Vol.1//Rebirth                                       0   \n",
       ".hack//G.U. Vol.2//Reminisce                                     0   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)                          0   \n",
       ".hack//G.U. Vol.3//Redemption                                    0   \n",
       "\n",
       "                                         Publisher_mixi, Inc  \\\n",
       "Name                                                           \n",
       "'98 Koshien                                                0   \n",
       ".hack//G.U. Vol.1//Rebirth                                 0   \n",
       ".hack//G.U. Vol.2//Reminisce                               0   \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)                    0   \n",
       ".hack//G.U. Vol.3//Redemption                              0   \n",
       "\n",
       "                                         Publisher_responDESIGN  \n",
       "Name                                                             \n",
       "'98 Koshien                                                   0  \n",
       ".hack//G.U. Vol.1//Rebirth                                    0  \n",
       ".hack//G.U. Vol.2//Reminisce                                  0  \n",
       ".hack//G.U. Vol.2//Reminisce (jp sales)                       0  \n",
       ".hack//G.U. Vol.3//Redemption                                 0  \n",
       "\n",
       "[5 rows x 574 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Scale all of the numeric data to prevent bias in the model\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_onehot[[\"Year\", \"NA_Sales\", \"EU_Sales\", \"JP_Sales\", \"Other_Sales\", \"Global_Sales\"]] = scaler.fit_transform(df_onehot[[\"Year\", \"NA_Sales\", \"EU_Sales\", \"JP_Sales\", \"Other_Sales\", \"Global_Sales\"]])\n",
    "\n",
    "df_onehot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3317c6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Publisher_10TACLE Studios</th>\n",
       "      <th>Publisher_1C Company</th>\n",
       "      <th>Publisher_20th Century Fox Video Games</th>\n",
       "      <th>Publisher_2D Boy</th>\n",
       "      <th>...</th>\n",
       "      <th>Publisher_Zoo Games</th>\n",
       "      <th>Publisher_Zushi Games</th>\n",
       "      <th>Publisher_bitComposer Games</th>\n",
       "      <th>Publisher_dramatic create</th>\n",
       "      <th>Publisher_fonfun</th>\n",
       "      <th>Publisher_iWin</th>\n",
       "      <th>Publisher_id Software</th>\n",
       "      <th>Publisher_imageepoch Inc.</th>\n",
       "      <th>Publisher_mixi, Inc</th>\n",
       "      <th>Publisher_responDESIGN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.132500e+04</td>\n",
       "      <td>1.132500e+04</td>\n",
       "      <td>1.132500e+04</td>\n",
       "      <td>1.132500e+04</td>\n",
       "      <td>1.132500e+04</td>\n",
       "      <td>1.132500e+04</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.648773e-14</td>\n",
       "      <td>2.886090e-17</td>\n",
       "      <td>-1.129339e-17</td>\n",
       "      <td>-1.003857e-17</td>\n",
       "      <td>3.638983e-17</td>\n",
       "      <td>-1.380304e-17</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000044e+00</td>\n",
       "      <td>1.000044e+00</td>\n",
       "      <td>1.000044e+00</td>\n",
       "      <td>1.000044e+00</td>\n",
       "      <td>1.000044e+00</td>\n",
       "      <td>1.000044e+00</td>\n",
       "      <td>0.016274</td>\n",
       "      <td>0.016274</td>\n",
       "      <td>0.021008</td>\n",
       "      <td>0.009397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049664</td>\n",
       "      <td>0.033863</td>\n",
       "      <td>0.016274</td>\n",
       "      <td>0.021008</td>\n",
       "      <td>0.009397</td>\n",
       "      <td>0.009397</td>\n",
       "      <td>0.009397</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.009397</td>\n",
       "      <td>0.009397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.203117e+00</td>\n",
       "      <td>-3.263087e-01</td>\n",
       "      <td>-2.788043e-01</td>\n",
       "      <td>-2.919486e-01</td>\n",
       "      <td>-2.542950e-01</td>\n",
       "      <td>-3.427877e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-5.958288e-01</td>\n",
       "      <td>-3.263087e-01</td>\n",
       "      <td>-2.788043e-01</td>\n",
       "      <td>-2.919486e-01</td>\n",
       "      <td>-2.542950e-01</td>\n",
       "      <td>-3.206166e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.240095e-01</td>\n",
       "      <td>-2.669753e-01</td>\n",
       "      <td>-2.527436e-01</td>\n",
       "      <td>-2.919486e-01</td>\n",
       "      <td>-2.180453e-01</td>\n",
       "      <td>-2.629717e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.159125e-01</td>\n",
       "      <td>-7.202264e-02</td>\n",
       "      <td>-1.094093e-01</td>\n",
       "      <td>-1.120046e-01</td>\n",
       "      <td>-1.092963e-01</td>\n",
       "      <td>-7.229999e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.355589e+00</td>\n",
       "      <td>3.484145e+01</td>\n",
       "      <td>3.753539e+01</td>\n",
       "      <td>2.597989e+01</td>\n",
       "      <td>3.860535e+01</td>\n",
       "      <td>3.634156e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 572 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Year      NA_Sales      EU_Sales      JP_Sales   Other_Sales  \\\n",
       "count  1.132500e+04  1.132500e+04  1.132500e+04  1.132500e+04  1.132500e+04   \n",
       "mean   1.648773e-14  2.886090e-17 -1.129339e-17 -1.003857e-17  3.638983e-17   \n",
       "std    1.000044e+00  1.000044e+00  1.000044e+00  1.000044e+00  1.000044e+00   \n",
       "min   -4.203117e+00 -3.263087e-01 -2.788043e-01 -2.919486e-01 -2.542950e-01   \n",
       "25%   -5.958288e-01 -3.263087e-01 -2.788043e-01 -2.919486e-01 -2.542950e-01   \n",
       "50%    2.240095e-01 -2.669753e-01 -2.527436e-01 -2.919486e-01 -2.180453e-01   \n",
       "75%    7.159125e-01 -7.202264e-02 -1.094093e-01 -1.120046e-01 -1.092963e-01   \n",
       "max    2.355589e+00  3.484145e+01  3.753539e+01  2.597989e+01  3.860535e+01   \n",
       "\n",
       "       Global_Sales  Publisher_10TACLE Studios  Publisher_1C Company  \\\n",
       "count  1.132500e+04               11325.000000          11325.000000   \n",
       "mean  -1.380304e-17                   0.000265              0.000265   \n",
       "std    1.000044e+00                   0.016274              0.016274   \n",
       "min   -3.427877e-01                   0.000000              0.000000   \n",
       "25%   -3.206166e-01                   0.000000              0.000000   \n",
       "50%   -2.629717e-01                   0.000000              0.000000   \n",
       "75%   -7.229999e-02                   0.000000              0.000000   \n",
       "max    3.634156e+01                   1.000000              1.000000   \n",
       "\n",
       "       Publisher_20th Century Fox Video Games  Publisher_2D Boy  ...  \\\n",
       "count                            11325.000000      11325.000000  ...   \n",
       "mean                                 0.000442          0.000088  ...   \n",
       "std                                  0.021008          0.009397  ...   \n",
       "min                                  0.000000          0.000000  ...   \n",
       "25%                                  0.000000          0.000000  ...   \n",
       "50%                                  0.000000          0.000000  ...   \n",
       "75%                                  0.000000          0.000000  ...   \n",
       "max                                  1.000000          1.000000  ...   \n",
       "\n",
       "       Publisher_Zoo Games  Publisher_Zushi Games  \\\n",
       "count         11325.000000           11325.000000   \n",
       "mean              0.002472               0.001148   \n",
       "std               0.049664               0.033863   \n",
       "min               0.000000               0.000000   \n",
       "25%               0.000000               0.000000   \n",
       "50%               0.000000               0.000000   \n",
       "75%               0.000000               0.000000   \n",
       "max               1.000000               1.000000   \n",
       "\n",
       "       Publisher_bitComposer Games  Publisher_dramatic create  \\\n",
       "count                 11325.000000               11325.000000   \n",
       "mean                      0.000265                   0.000442   \n",
       "std                       0.016274                   0.021008   \n",
       "min                       0.000000                   0.000000   \n",
       "25%                       0.000000                   0.000000   \n",
       "50%                       0.000000                   0.000000   \n",
       "75%                       0.000000                   0.000000   \n",
       "max                       1.000000                   1.000000   \n",
       "\n",
       "       Publisher_fonfun  Publisher_iWin  Publisher_id Software  \\\n",
       "count      11325.000000    11325.000000           11325.000000   \n",
       "mean           0.000088        0.000088               0.000088   \n",
       "std            0.009397        0.009397               0.009397   \n",
       "min            0.000000        0.000000               0.000000   \n",
       "25%            0.000000        0.000000               0.000000   \n",
       "50%            0.000000        0.000000               0.000000   \n",
       "75%            0.000000        0.000000               0.000000   \n",
       "max            1.000000        1.000000               1.000000   \n",
       "\n",
       "       Publisher_imageepoch Inc.  Publisher_mixi, Inc  Publisher_responDESIGN  \n",
       "count               11325.000000         11325.000000            11325.000000  \n",
       "mean                    0.000177             0.000088                0.000088  \n",
       "std                     0.013289             0.009397                0.009397  \n",
       "min                     0.000000             0.000000                0.000000  \n",
       "25%                     0.000000             0.000000                0.000000  \n",
       "50%                     0.000000             0.000000                0.000000  \n",
       "75%                     0.000000             0.000000                0.000000  \n",
       "max                     1.000000             1.000000                1.000000  \n",
       "\n",
       "[8 rows x 572 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_onehot.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7430ca",
   "metadata": {},
   "source": [
    "These metrics are useful to quantify the numeric data, but they do nothing for the categorical data. The histogram below shows the distribution of the genre data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03c49285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(font_scale = .5)\n",
    "sns.histplot(df.Genre)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ebbb6a",
   "metadata": {},
   "source": [
    "Our final dataset includes the following data:\n",
    "\n",
    "-Name stored as a string\n",
    "\n",
    "-Year stored as a float and scaled\n",
    "\n",
    "-Genre stored as a string\n",
    "\n",
    "-NA_Sales, EU_Sales, JP_Sales, Other_Sales, and Global_Sales all stored as a float and scaled\n",
    "\n",
    "-Publisher stored as a one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c79e080",
   "metadata": {},
   "source": [
    "## 3. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75f90ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "\n",
    "# Binary Logistic Regression using vectorized implementation\n",
    "\n",
    "class BinaryLogisticRegression:\n",
    "    # Adjust default values for iterations and C as needed\n",
    "    def __init__(self, eta, iterations=20, C=0.001, penalty='l2'):\n",
    "        self.eta = eta          # The learning rate\n",
    "        self.iterations = iterations\n",
    "        self.C = C\n",
    "        self.penalty = penalty\n",
    "    def __str__(self):\n",
    "        if(hasattr(self, 'weights_')):\n",
    "            return \"Binary Logistic Regression Object with coefficients:\\n\" + str(self.weights_)\n",
    "        return 'Binary Logistic Regression Object is untrained'\n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_bias(X):\n",
    "        # Add a column of float ones to X\n",
    "        return np.hstack((np.ones((X.shape[0],1)), X))\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        return expit(theta)\n",
    "    \n",
    "    def _get_gradient(self, X, y):\n",
    "        y_diff = y - self.predict_proba(X, add_bias=False).ravel()\n",
    "        gradient = np.mean(X * y_diff[:,np.newaxis], axis = 0)\n",
    "        gradient = gradient.reshape(self.weights_.shape)\n",
    "        # Based on penalty type, add the appropriate term to the gradient\n",
    "        if self.penalty == 'l1':\n",
    "            # Double check this, not sure\n",
    "            gradient[1:] += self.C * sum(abs(self.weights_[1:]))\n",
    "        elif self.penalty == 'l2':\n",
    "            # Double check this, not sure\n",
    "            gradient[1:] += self.C * sum(self.weights_[1:]**2)\n",
    "        elif self.penalty == 'both':\n",
    "            gradient[1:] += self.C * sum(self.weights_[1:]**2) + self.C * sum(abs(self.weights_[1:]))\n",
    "        elif self.penalty == 'none':\n",
    "            pass\n",
    "        return gradient\n",
    "    \n",
    "    def predict_proba(self, X, add_bias=True):\n",
    "        X_bias = self._add_bias(X) if add_bias else X\n",
    "        return self._sigmoid(X_bias @ self.weights_)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return (self.predict_proba(X) > 0.5)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X_bias = self._add_bias(X)\n",
    "        num_samples, num_features = X_bias.shape\n",
    "        self.weights_ = np.zeros((num_features,1))    # Creating the weight vector\n",
    "\n",
    "        for _ in range(self.iterations):\n",
    "            gradient = self._get_gradient(X_bias, y)\n",
    "            self.weights_ += self.eta * gradient\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b3c0d9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import ma\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "## Optimizing 1: Steepest Ascent/Line Search\n",
    "\n",
    "class LineSearchLogisticRegression(BinaryLogisticRegression):\n",
    "    def __init__(self, line_iterations=0.0, **kwds):\n",
    "        self.line_iterations = line_iterations\n",
    "        super().__init__(**kwds)\n",
    "\n",
    "        @staticmethod\n",
    "        def objective_function(eta, X, y, w, gradient, C):\n",
    "            w_new = w - gradient*eta\n",
    "            gradient_new = expit(X @ w_new)\n",
    "            return -np.sum(ma.log(gradient_new[y==1]))-ma.sum(ma.log(1-gradient_new[y==0])) + C*sum(w_new**2)\n",
    "        \n",
    "        def fit(self, X, y):\n",
    "            X_bias = self._add_bias(X)\n",
    "            num_samples, num_features = X_bias.shape\n",
    "            self.weights_ = np.zeros((num_features,1))\n",
    "\n",
    "            for _ in range (self.iterations):\n",
    "                gradient = -self._get_gradient(X_bias, y)\n",
    "                opts = {'maxiter': self.line_iterations}\n",
    "                res = minimize_scalar(self.objective_function,\n",
    "                                      bounds=(0,self.eta*10),\n",
    "                                      args=(X_bias, y, self.weights_, gradient, self.C),\n",
    "                                      method='bounded',\n",
    "                                      options=opts)\n",
    "                \n",
    "            eta = res.x\n",
    "            self.weights_ -= eta*gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "97292144",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optimizing 2: Stoachastic Gradient Ascent\n",
    "\n",
    "class StochasticLogisticRegression(BinaryLogisticRegression):\n",
    "    def _get_gradient(self, X, y):\n",
    "        # Adjust batch size as needed, calculates gradient according to this batch size\n",
    "        batch_size = 16\n",
    "        idxs = np.random.choice(len(y), batch_size)\n",
    "\n",
    "        y_diff = y[idxs] - self.predict_proba(X[idxs], add_bias=False).ravel()\n",
    "        gradient= np.mean(X[idxs] * y_diff[:,np.newaxis], axis = 0)\n",
    "\n",
    "        gradient = gradient.reshape(self.weights_.shape)\n",
    "        if self.penalty == 'l1':\n",
    "            # Double check this, not sure\n",
    "            gradient[1:] += self.C * sum(abs(self.weights_[1:]))\n",
    "        elif self.penalty == 'l2':\n",
    "            # Double check this, not sure\n",
    "            gradient[1:] += self.C * sum(self.weights_[1:]**2)\n",
    "        elif self.penalty == 'both':\n",
    "            gradient[1:] += self.C * sum(self.weights_[1:]**2) + self.C * sum(abs(self.weights_[1:]))\n",
    "        elif self.penalty == 'none':\n",
    "            pass\n",
    "\n",
    "        # This might need to be negative?\n",
    "        return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d85c91a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fmin_bfgs\n",
    "## Optimizing 3: Quasi-Newton Method (BFGS)\n",
    "\n",
    "class BFGSLogisticRegression(BinaryLogisticRegression):\n",
    "\n",
    "    @staticmethod\n",
    "    def objective_function(w, X, y, C, penalty):\n",
    "        gradient = expit(X @ w)\n",
    "        return -ma.sum(ma.log(gradient[y==1])-ma.sum(ma.log(1-gradient[y==0]))) + C*sum(w**2)\n",
    "    \n",
    "    @staticmethod\n",
    "    def objective_gradient(w, X, y, C, penalty):\n",
    "        gradient = expit(X @ w)\n",
    "        y_diff = y-gradient\n",
    "        gradient = np.mean(X * y_diff[:,np.newaxis], axis = 0)\n",
    "        gradient = gradient.reshape(w.shape)\n",
    "        if penalty == 'l1':\n",
    "            # Double check this, not sure\n",
    "            gradient[1:] += C * sum(abs(w[1:]))\n",
    "        elif penalty == 'l2':\n",
    "            # Double check this, not sure\n",
    "            gradient[1:] += C * sum(w[1:]**2)\n",
    "        elif penalty == 'both':\n",
    "            gradient[1:] += C * sum(w[1:]**2) + C * sum(abs(w[1:]))\n",
    "        elif penalty == 'none':\n",
    "            pass\n",
    "        return -gradient\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X_bias = self._add_bias(X)\n",
    "        num_samples, num_features = X_bias.shape\n",
    "        self.weights_ = fmin_bfgs(self.objective_function,\n",
    "                                  np.zeros((num_features,1)),\n",
    "                                  fprime=self.objective_gradient,\n",
    "                                  args=(X_bias, y, self.C, self.penalty),\n",
    "                                  gtol=1e-03,\n",
    "                                  maxiter=self.iterations,\n",
    "                                  disp=False)\n",
    "        self.weights_ = self.weights_.reshape((num_features,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "43e435ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regularized Logistic Regression using vectorized implementation\n",
    "class MultiClassLogisticRegression:\n",
    "    # Adjust default values for iterations and C as needed, temp default for solver is LineSearchLogisticRegression\n",
    "    # Penalty can be either 'l1' or 'l2' or 'both', default to 'l2' for now (these are passed to the solver)\n",
    "    def __init__(self, **kwds):\n",
    "        self.eta = kwds.get('eta', 0.01)  # The learning rate\n",
    "        self.iterations = kwds.get('iterations', 20)\n",
    "        self.line_iterations = kwds.get('line_iterations', 0.0)\n",
    "        self.C = kwds.get('C', 0.001)\n",
    "        self.penalty = kwds.get('penalty', 'l2')\n",
    "        self.solver = kwds.get('solver', LineSearchLogisticRegression)\n",
    "        self.classifiers_ = []\n",
    "\n",
    "    def __str__(self):\n",
    "        if(hasattr(self, 'weights_')):\n",
    "            return \"Multiclass Logistic Regression Object with coefficients:\\n\" + str(self.weights_)\n",
    "        return 'Multiclass Logistic Regression Object is untrained'\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.unique_classes_ = np.sort(np.unique(y))\n",
    "        num_unique_classes = len(self.unique_classes_)\n",
    "        self.classifiers_ = []\n",
    "\n",
    "        for i, y_value in enumerate(self.unique_classes_):\n",
    "            # One vs All\n",
    "            y_binary = np.array(y==y_value).astype(int)\n",
    "            # Only pass line_iterations to solver if it is not 0.0\n",
    "            \n",
    "            if self.line_iterations == 0.0:\n",
    "                lr = self.solver(eta=self.eta, iterations=self.iterations, C=self.C, penalty=self.penalty)\n",
    "            else:\n",
    "                lr = self.solver(eta=self.eta, iterations=self.iterations, line_iterations=self.line_iterations, C=self.C, penalty=self.penalty)\n",
    "            lr.fit(X, y_binary)\n",
    "            self.classifiers_.append(lr)\n",
    "        \n",
    "        self.weights_ = np.hstack([x.weights_ for x in self.classifiers_]).T\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        probabilities = []\n",
    "        for lr in self.classifiers_:\n",
    "            probabilities.append(lr.predict_proba(X).reshape((len(X),1)))\n",
    "        return np.hstack(probabilities)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.unique_classes_[np.argmax(self.predict_proba(X), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "457cfc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Logistic Regression Object with coefficients:\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Accuracy: 16.16%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.MultiClassLogisticRegression at 0x1bc95f55110>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "if \"Name\" in df_onehot:\n",
    "    del df_onehot[\"Name\"]\n",
    "y = df_onehot[\"Genre\"]\n",
    "X = df_onehot.drop(columns=[\"Genre\"])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Need to address the categorical variables in the data, represent them as binary variables somehow\n",
    "\n",
    "# Extra parameter line_iterations only used for LineSearchLogisticRegression\n",
    "\n",
    "# mlr = MultiClassLogisticRegression(eta=0.5, \n",
    "#                                    iterations=4, \n",
    "#                                    line_iterations=0.0,\n",
    "#                                    C=0.01, \n",
    "#                                    solver=LineSearchLogisticRegression, \n",
    "#                                    penalty='l2')\n",
    "\n",
    "mlr = MultiClassLogisticRegression( \n",
    "                                   iterations=2, \n",
    "                                   C=0.001, \n",
    "                                   solver=BFGSLogisticRegression, \n",
    "                                   penalty='both')\n",
    "\n",
    "mlr.fit(X_train, y_train)\n",
    "print(mlr)\n",
    "accuracy = accuracy_score(y_test, mlr.predict(X_test)) * 100\n",
    "print(f'Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd9ebb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.33934416 -5.1767324  -3.35971961 ... -2.84539243  8.73340959\n",
      "  -1.90949502]\n",
      " [ 0.12139754  6.09249445  4.89613351 ...  4.25133207 -1.4569113\n",
      "  -1.8157169 ]\n",
      " [-0.19057947 11.35529795  7.22237029 ... -0.7342689  -0.4614676\n",
      "  -0.58229646]\n",
      " ...\n",
      " [ 0.2368382   0.65897907  0.8790814  ... -1.75479147 -1.49724446\n",
      "  -1.01107515]\n",
      " [-0.19697584  1.80709008  1.14975653 ... -1.46842219 -0.97837489\n",
      "   9.97144767]\n",
      " [-0.12229006  0.34438417  1.63275566 ... -1.08370206 -0.6538758\n",
      "  -0.76747038]]\n",
      "Accuracy of:  0.34852097130242826\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "y_not_binary = y # note problem is NOT binary anymore, there are three classes!\n",
    "\n",
    "lr_sk = LogisticRegression(solver='liblinear',n_jobs=1,\n",
    "                           multi_class='ovr', C = 1/0.001, \n",
    "                           penalty='l2',\n",
    "                           max_iter=100) # all params default\n",
    "\n",
    "lr_sk.fit(X, y_not_binary) # no need to add bias term, sklearn does it internally!!\n",
    "print(lr_sk.coef_)\n",
    "yhat = lr_sk.predict(X)\n",
    "print('Accuracy of: ',accuracy_score(y_not_binary,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32cd98b",
   "metadata": {},
   "source": [
    "## 4. Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650c0df6",
   "metadata": {},
   "source": [
    "## 5. Exceptional Work (rename to what we actually end up doing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ee83e623",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BFGS from scratch\n",
    "\n",
    "class BFGSBinaryLogisticRegressionScratch(BinaryLogisticRegression):\n",
    "    \n",
    "    @staticmethod\n",
    "    def objective_function(w,X,y,C,penalty):\n",
    "        gradient = expit(X @ w)\n",
    "        # invert this because scipy minimizes, but we derived all formulas for maximzing\n",
    "        return -ma.sum(ma.log(gradient[y==1]))-ma.sum(ma.log(1-gradient[y==0])) + C*sum(w**2) \n",
    "\n",
    "    @staticmethod\n",
    "    def objective_gradient(w,X,y,C,penalty):\n",
    "        gradient = expit(X @ w)\n",
    "        ydiff = y-gradient # get y difference\n",
    "        print(\"HERE\")\n",
    "        print(ydiff)\n",
    "        print(ydiff.shape)\n",
    "        print()\n",
    "        print(\"SECOND\")\n",
    "        print(X)\n",
    "        print(X.shape)\n",
    "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0)\n",
    "        gradient = gradient.reshape(w.shape)\n",
    "        if penalty == 'l1':\n",
    "            # Double check this, not sure\n",
    "            gradient[1:] += C * sum(abs(w[1:]))\n",
    "        elif penalty == 'l2':\n",
    "            # Double check this, not sure\n",
    "            gradient[1:] += C * sum(w[1:]**2)\n",
    "        elif penalty == 'both':\n",
    "            gradient[1:] += C * sum(w[1:]**2) + C * sum(abs(w[1:]))\n",
    "        elif penalty == 'none':\n",
    "            pass\n",
    "        return -gradient\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X_bias = self._add_bias(X) # add bias term\n",
    "        num_samples, num_features = X_bias.shape\n",
    "        # Initialization (Step 1)\n",
    "        self.weights_ = np.zeros((num_features,1))\n",
    "        # Set initial Hessian to identity matrix\n",
    "        hessian = np.identity(num_features)\n",
    "        inv_hessian = np.linalg.inv(hessian)\n",
    "        # Iterate through the number of iterations\n",
    "        for _ in range(self.iterations):\n",
    "            # Set p_k equal to the negative inverse hessian times the gradient (Step 2)\n",
    "            gradient_old = self.objective_gradient(self.weights_, X_bias, y, self.C, self.penalty)\n",
    "            p_k = -inv_hessian @ gradient_old\n",
    "            # Update weights (Step 3)\n",
    "            self.weights_ += self.eta * p_k\n",
    "            # Save the scaled direction (Step 4)\n",
    "            s_k = self.eta * p_k\n",
    "            # Approximate the change in the derivative (Step 5a)\n",
    "            v_k = self.objective_gradient(self.weights_, X_bias, y, self.C) - gradient_old\n",
    "            # Define u_k (Step 5b)\n",
    "            u_k = v_k - hessian @ s_k\n",
    "            # Redfine the approximate hessian update (Step 6)\n",
    "            hessian += (v_k @ v_k.T)/(v_k.T @ s_k) - (hessian @ s_k @ s_k.T @ hessian)/(s_k.T @ hessian @ s_k)\n",
    "            # Approximate the inverse hessian (Step 7)\n",
    "            inv_hessian += (s_k.T @ v_k + inv_hessian)(s_k @ s_k.T)/(s_k.T @ v_k)**2 - (inv_hessian @ v_k @ s_k.T + s_k @ v_k.T @ inv_hessian)/(s_k.T @ v_k)\n",
    "\n",
    "        self.weights_ = self.weights_.reshape((num_features,1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f719bd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HERE\n",
      "[[-0.5 -0.5 -0.5 ...  0.5  0.5 -0.5]\n",
      " [-0.5 -0.5 -0.5 ...  0.5  0.5 -0.5]\n",
      " [-0.5 -0.5 -0.5 ...  0.5  0.5 -0.5]\n",
      " ...\n",
      " [-0.5 -0.5 -0.5 ...  0.5  0.5 -0.5]\n",
      " [-0.5 -0.5 -0.5 ...  0.5  0.5 -0.5]\n",
      " [-0.5 -0.5 -0.5 ...  0.5  0.5 -0.5]]\n",
      "(9060, 9060)\n",
      "\n",
      "SECOND\n",
      "[[ 1.         -0.43186113 -0.28392767 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.         -1.25169943 -0.29240387 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.         -1.25169943  1.02988352 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 1.         -1.57963475 -0.30935627 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.          0.38797716 -0.25002286 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.         -0.43186113 -0.32630867 ...  0.          0.\n",
      "   0.        ]]\n",
      "(9060, 573)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (9060,573) (9060,1,9060) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m### NOTE: Above code has not been tested yet, this is just a rough draft\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m### Commented out for now as it most likely doesn't work yet\u001b[39;00m\n\u001b[0;32m      4\u001b[0m bfgslr \u001b[38;5;241m=\u001b[39m MultiClassLogisticRegression(eta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m      5\u001b[0m                                       iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m      6\u001b[0m                                       C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[0;32m      7\u001b[0m                                       solver\u001b[38;5;241m=\u001b[39mBFGSBinaryLogisticRegressionScratch)\n\u001b[1;32m----> 9\u001b[0m bfgslr\u001b[38;5;241m.\u001b[39mfit(X_train,y_train)\n\u001b[0;32m     10\u001b[0m yhat \u001b[38;5;241m=\u001b[39m bfgslr\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(bfgslr)\n",
      "Cell \u001b[1;32mIn[56], line 34\u001b[0m, in \u001b[0;36mMultiClassLogisticRegression.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m         lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver(eta\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meta, iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterations, line_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline_iterations, C\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC, penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpenalty)\n\u001b[1;32m---> 34\u001b[0m     lr\u001b[38;5;241m.\u001b[39mfit(X, y_binary)\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifiers_\u001b[38;5;241m.\u001b[39mappend(lr)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([x\u001b[38;5;241m.\u001b[39mweights_ \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifiers_])\u001b[38;5;241m.\u001b[39mT\n",
      "Cell \u001b[1;32mIn[59], line 47\u001b[0m, in \u001b[0;36mBFGSBinaryLogisticRegressionScratch.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Iterate through the number of iterations\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterations):\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m# Set p_k equal to the negative inverse hessian times the gradient (Step 2)\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m     gradient_old \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective_gradient(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights_, X_bias, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpenalty)\n\u001b[0;32m     48\u001b[0m     p_k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39minv_hessian \u001b[38;5;241m@\u001b[39m gradient_old\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# Update weights (Step 3)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[59], line 22\u001b[0m, in \u001b[0;36mBFGSBinaryLogisticRegressionScratch.objective_gradient\u001b[1;34m(w, X, y, C, penalty)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(X)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 22\u001b[0m gradient \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(X \u001b[38;5;241m*\u001b[39m ydiff[:,np\u001b[38;5;241m.\u001b[39mnewaxis], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     23\u001b[0m gradient \u001b[38;5;241m=\u001b[39m gradient\u001b[38;5;241m.\u001b[39mreshape(w\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m penalty \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# Double check this, not sure\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (9060,573) (9060,1,9060) "
     ]
    }
   ],
   "source": [
    "### NOTE: Above code has not been tested yet, this is just a rough draft\n",
    "### Commented out for now as it most likely doesn't work yet\n",
    "\n",
    "bfgslr = MultiClassLogisticRegression(eta=1,\n",
    "                                      iterations=3,\n",
    "                                      C=0.001,\n",
    "                                      solver=BFGSBinaryLogisticRegressionScratch)\n",
    "\n",
    "bfgslr.fit(X_train,y_train)\n",
    "yhat = bfgslr.predict(X_test)\n",
    "print(bfgslr)\n",
    "print('Accuracy of: ',accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf4494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compare to sklearn implementation\n",
    "\n",
    "lr_sk = LogisticRegression(solver='lbfgs',n_jobs=1,\n",
    "                           multi_class='ovr', \n",
    "                           C = 1/0.001, \n",
    "                           penalty='l2',\n",
    "                          max_iter=50) \n",
    "\n",
    "\n",
    "lr_sk.fit(X_train, y_train) \n",
    "print(lr_sk.coef_)\n",
    "yhat = lr_sk.predict(X_test)\n",
    "print('Accuracy of: ',accuracy_score(y_test,yhat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
